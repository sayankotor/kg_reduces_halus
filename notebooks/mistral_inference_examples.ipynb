{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51f5a1e2-3069-4e4f-b972-ca67e249d6bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading shards: 100%|██████████| 2/2 [00:00<00:00, 950.34it/s]\n",
      "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]/home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from urllib.request import urlopen\n",
    "import torch.nn as nn\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "# Loading some sources of the projection adapter and image encoder\n",
    "hf_hub_download(repo_id=\"AIRI-Institute/OmniFusion\", filename=\"models.py\", local_dir='./')\n",
    "from models import CLIPVisionTower\n",
    "\n",
    "DEVICE = \"cuda:0\"\n",
    "PROMPT = \"This is a dialog with AI assistant.\\n\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"AIRI-Institute/OmniFusion\", subfolder=\"OmniMistral-tokenizer\", use_fast=False)\n",
    "model = AutoModelForCausalLM.from_pretrained(\"AIRI-Institute/OmniFusion\", subfolder=\"OmniMistral-model\", torch_dtype=torch.bfloat16, device_map=DEVICE)\n",
    "\n",
    "#hf_hub_download(repo_id=\"AIRI-Institute/OmniFusion\", filename=\"projection\", local_dir='./')\n",
    "#hf_hub_download(repo_id=\"AIRI-Institute/OmniFusion\", filename=\"special_embeddings.pt\", local_dir='./')\n",
    "projection = torch.load(\"/home/jovyan/shares/SR004.nfs2/chekalina/check_halu/ckpts/projection_qa1\", map_location=DEVICE)\n",
    "start_emb = torch.load(\"/home/jovyan/shares/SR004.nfs2/chekalina/check_halu/ckpts/SOI2_qa1.pt\", map_location=DEVICE)\n",
    "end_emb = torch.load(\"/home/jovyan/shares/SR004.nfs2/chekalina/check_halu/ckpts/EOI2_qa1.pt\", map_location=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c522c1b5-8a32-4dab-8ebf-d8b922e1285b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a8dcac-2524-4b7e-9d07-c886dc722cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login(token='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')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fffb75dc-89f7-4729-999c-7a55f53bc98f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /home/jovyan/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login(token='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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ae5b4cc-f153-48fc-bd40-67fb9cf9bb7e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e719f88de2f4c468ede3c67367e4f0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13b2462efe8a4b419eb6dd1380015c98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d375656557db41a0be4c145bd8c8d540",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc9104112b294f798463471bdf8f6129",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8933863cc9af40849495f8a50c5a4389",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7723428431f4a2c93ae7f473f861811",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1524107ae1aa42bf83be689fd7c5c804",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login(token='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')\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from urllib.request import urlopen\n",
    "import torch.nn as nn\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "# Loading some sources of the projection adapter and image encoder\n",
    "#hf_hub_download(repo_id=\"mistralai/Mistral-7B-v0.1\", filename=\"models.py\", local_dir='./')\n",
    "from models import CLIPVisionTower\n",
    "\n",
    "DEVICE = \"cuda:0\"\n",
    "PROMPT = \"This is a dialog with AI assistant.\\n\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-v0.1\", use_fast=False)\n",
    "model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-v0.1\", torch_dtype=torch.bfloat16, device_map=DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d80c4f3-8f49-4a0f-8228-52afffd20474",
   "metadata": {},
   "outputs": [],
   "source": [
    "mistralai/Mistral-7B-v0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1285b147-2983-4cee-9c07-681caa023d74",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.39.3\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98867802-97ae-49a9-ba6f-f0e572a3dcd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "786933ae-087d-4a9a-9643-0cff81aa7cc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\")\n",
    "model_path = \"/home/jovyan/shares/SR004.nfs2/razzhigaev/KG/graphRoberta_v1\"\n",
    "projector_path = \"/home/jovyan/shares/SR004.nfs2/razzhigaev/KG/projector_v1\"\n",
    "\n",
    "\n",
    "tokenizer_emb = AutoTokenizer.from_pretrained(model_path)\n",
    "model_emb = AutoModelForMaskedLM.from_pretrained(model_path).to(DEVICE)\n",
    "projector = torch.load(projector_path).to(DEVICE)\n",
    "def text2graph_emb(text):\n",
    "    with torch.no_grad():\n",
    "        input_ids = tokenizer_emb.encode(text, return_tensors=\"pt\").to(DEVICE)\n",
    "        output = model_emb(input_ids, output_hidden_states=True)\n",
    "        pooled_emb = output[\"hidden_states\"][-1].mean(1)\n",
    "        projected_emb = projector(pooled_emb)\n",
    "    \n",
    "    return projected_emb\n",
    "\n",
    "text = \"Vladimir Putin\"\n",
    "predicted_graph_embedding = text2graph_emb(text).to(torch.bfloat16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a917fc51-0eb6-4914-8c0e-1803d52e0584",
   "metadata": {},
   "source": [
    "## 1 Load main dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3c0a5d7-b003-45a5-a536-73ae2f09e46b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 3.45M/3.45M [00:00<00:00, 3.73MB/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80c1549838674f71b8393509e333c7c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating data split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"pminervini/HaluEval\",'dialogue') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3d21cca-41b8-4c30-9751-1201a4f33889",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'llama_recipes.datasets.utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_recipes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Concatenator\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'llama_recipes.datasets.utils'"
     ]
    }
   ],
   "source": [
    "from llama_recipes.datasets.utils import Concatenator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8964954-5f43-4982-8699-9c5c17f66786",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting llama-recipes\n",
      "  Downloading llama_recipes-0.0.2-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: accelerate in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from llama-recipes) (0.29.2)\n",
      "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='developer.download.nvidia.com', port=443): Read timed out. (read timeout=15)\")': /compute/redist/appdirs/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='developer.download.nvidia.com', port=443): Read timed out. (read timeout=15)\")': /compute/redist/appdirs/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='developer.download.nvidia.com', port=443): Read timed out. (read timeout=15)\")': /compute/redist/appdirs/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='developer.download.nvidia.com', port=443): Read timed out. (read timeout=15)\")': /compute/redist/appdirs/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='developer.download.nvidia.com', port=443): Read timed out. (read timeout=15)\")': /compute/redist/appdirs/\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting appdirs (from llama-recipes)\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting bitsandbytes (from llama-recipes)\n",
      "  Downloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl.metadata (2.2 kB)\n",
      "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='developer.download.nvidia.com', port=443): Read timed out. (read timeout=15)\")': /compute/redist/black/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='developer.download.nvidia.com', port=443): Read timed out. (read timeout=15)\")': /compute/redist/black/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='developer.download.nvidia.com', port=443): Read timed out. (read timeout=15)\")': /compute/redist/black/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='developer.download.nvidia.com', port=443): Read timed out. (read timeout=15)\")': /compute/redist/black/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='developer.download.nvidia.com', port=443): Read timed out. (read timeout=15)\")': /compute/redist/black/\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting black (from llama-recipes)\n",
      "  Downloading black-24.4.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (77 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='developer.download.nvidia.com', port=443): Read timed out. (read timeout=15)\")': /compute/redist/chardet/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='developer.download.nvidia.com', port=443): Read timed out. (read timeout=15)\")': /compute/redist/chardet/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='developer.download.nvidia.com', port=443): Read timed out. (read timeout=15)\")': /compute/redist/chardet/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='developer.download.nvidia.com', port=443): Read timed out. (read timeout=15)\")': /compute/redist/chardet/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='developer.download.nvidia.com', port=443): Read timed out. (read timeout=15)\")': /compute/redist/chardet/\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting chardet (from llama-recipes)\n",
      "  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: datasets in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from llama-recipes) (2.18.0)\n",
      "Collecting fire (from llama-recipes)\n",
      "  Downloading fire-0.6.0.tar.gz (88 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.4/88.4 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting gradio (from llama-recipes)\n",
      "  Downloading gradio-4.32.2-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting loralib (from llama-recipes)\n",
      "  Downloading loralib-0.1.2-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: matplotlib in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from llama-recipes) (3.8.3)\n",
      "Requirement already satisfied: openai in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from llama-recipes) (1.30.2)\n",
      "Collecting optimum (from llama-recipes)\n",
      "  Downloading optimum-1.20.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting peft (from llama-recipes)\n",
      "  Downloading peft-0.11.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting py7zr (from llama-recipes)\n",
      "  Downloading py7zr-0.21.0-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: scipy in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from llama-recipes) (1.12.0)\n",
      "Requirement already satisfied: sentencepiece in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from llama-recipes) (0.2.0)\n",
      "Requirement already satisfied: tabulate in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from llama-recipes) (0.9.0)\n",
      "Collecting torch>=2.2 (from llama-recipes)\n",
      "  Downloading torch-2.3.0-cp39-cp39-manylinux1_x86_64.whl.metadata (26 kB)\n",
      "Collecting transformers>=4.40.0 (from llama-recipes)\n",
      "  Downloading transformers-4.41.2-py3-none-any.whl.metadata (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='developer.download.nvidia.com', port=443): Read timed out. (read timeout=15)\")': /compute/redist/typing-extensions/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='developer.download.nvidia.com', port=443): Read timed out. (read timeout=15)\")': /compute/redist/typing-extensions/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='developer.download.nvidia.com', port=443): Read timed out. (read timeout=15)\")': /compute/redist/typing-extensions/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='developer.download.nvidia.com', port=443): Read timed out. (read timeout=15)\")': /compute/redist/typing-extensions/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='developer.download.nvidia.com', port=443): Read timed out. (read timeout=15)\")': /compute/redist/typing-extensions/\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting typing-extensions==4.8.0 (from llama-recipes)\n",
      "  Downloading typing_extensions-4.8.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: filelock in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from torch>=2.2->llama-recipes) (3.13.3)\n",
      "Requirement already satisfied: sympy in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from torch>=2.2->llama-recipes) (1.12)\n",
      "Requirement already satisfied: networkx in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from torch>=2.2->llama-recipes) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from torch>=2.2->llama-recipes) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from torch>=2.2->llama-recipes) (2024.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from torch>=2.2->llama-recipes) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from torch>=2.2->llama-recipes) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from torch>=2.2->llama-recipes) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from torch>=2.2->llama-recipes) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from torch>=2.2->llama-recipes) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from torch>=2.2->llama-recipes) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from torch>=2.2->llama-recipes) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from torch>=2.2->llama-recipes) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from torch>=2.2->llama-recipes) (12.1.0.106)\n",
      "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=2.2->llama-recipes)\n",
      "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from torch>=2.2->llama-recipes) (12.1.105)\n",
      "Collecting triton==2.3.0 (from torch>=2.2->llama-recipes)\n",
      "  Downloading triton-2.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.2->llama-recipes) (12.5.40)\n",
      "Collecting huggingface-hub<1.0,>=0.23.0 (from transformers>=4.40.0->llama-recipes)\n",
      "  Downloading huggingface_hub-0.23.2-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from transformers>=4.40.0->llama-recipes) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from transformers>=4.40.0->llama-recipes) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from transformers>=4.40.0->llama-recipes) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from transformers>=4.40.0->llama-recipes) (2023.12.25)\n",
      "Requirement already satisfied: requests in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from transformers>=4.40.0->llama-recipes) (2.28.2)\n",
      "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='developer.download.nvidia.com', port=443): Read timed out. (read timeout=15)\")': /compute/redist/tokenizers/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='developer.download.nvidia.com', port=443): Read timed out. (read timeout=15)\")': /compute/redist/tokenizers/\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting tokenizers<0.20,>=0.19 (from transformers>=4.40.0->llama-recipes)\n",
      "  Downloading tokenizers-0.19.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from transformers>=4.40.0->llama-recipes) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from transformers>=4.40.0->llama-recipes) (4.65.2)\n",
      "Requirement already satisfied: psutil in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from accelerate->llama-recipes) (5.9.0)\n",
      "Requirement already satisfied: click>=8.0.0 in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from black->llama-recipes) (8.1.7)\n",
      "Collecting mypy-extensions>=0.4.3 (from black->llama-recipes)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting pathspec>=0.9.0 (from black->llama-recipes)\n",
      "  Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: platformdirs>=2 in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from black->llama-recipes) (3.10.0)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from black->llama-recipes) (2.0.1)\n",
      "Requirement already satisfied: ipython>=7.8.0 in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from black[jupyter]->llama-recipes) (8.15.0)\n",
      "Collecting tokenize-rt>=3.2.0 (from black[jupyter]->llama-recipes)\n",
      "  Downloading tokenize_rt-5.2.0-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from datasets->llama-recipes) (15.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from datasets->llama-recipes) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from datasets->llama-recipes) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from datasets->llama-recipes) (2.2.1)\n",
      "Requirement already satisfied: xxhash in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from datasets->llama-recipes) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from datasets->llama-recipes) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from datasets->llama-recipes) (3.9.4)\n",
      "Requirement already satisfied: six in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from fire->llama-recipes) (1.16.0)\n",
      "Requirement already satisfied: termcolor in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from fire->llama-recipes) (2.4.0)\n",
      "Collecting aiofiles<24.0,>=22.0 (from gradio->llama-recipes)\n",
      "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting altair<6.0,>=4.2.0 (from gradio->llama-recipes)\n",
      "  Downloading altair-5.3.0-py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting fastapi (from gradio->llama-recipes)\n",
      "  Downloading fastapi-0.111.0-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting ffmpy (from gradio->llama-recipes)\n",
      "  Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='developer.download.nvidia.com', port=443): Read timed out. (read timeout=15)\")': /compute/redist/gradio-client/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='developer.download.nvidia.com', port=443): Read timed out. (read timeout=15)\")': /compute/redist/gradio-client/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='developer.download.nvidia.com', port=443): Read timed out. (read timeout=15)\")': /compute/redist/gradio-client/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='developer.download.nvidia.com', port=443): Read timed out. (read timeout=15)\")': /compute/redist/gradio-client/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='developer.download.nvidia.com', port=443): Read timed out. (read timeout=15)\")': /compute/redist/gradio-client/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[?25hCollecting gradio-client==0.17.0 (from gradio->llama-recipes)\n",
      "  Downloading gradio_client-0.17.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: httpx>=0.24.1 in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from gradio->llama-recipes) (0.27.0)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from gradio->llama-recipes) (6.4.0)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from gradio->llama-recipes) (2.1.5)\n",
      "Collecting orjson~=3.0 (from gradio->llama-recipes)\n",
      "  Downloading orjson-3.10.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (49 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pillow<11.0,>=8.0 in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from gradio->llama-recipes) (10.2.0)\n",
      "Requirement already satisfied: pydantic>=2.0 in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from gradio->llama-recipes) (2.7.1)\n",
      "Collecting pydub (from gradio->llama-recipes)\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting python-multipart>=0.0.9 (from gradio->llama-recipes)\n",
      "  Downloading python_multipart-0.0.9-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting ruff>=0.2.2 (from gradio->llama-recipes)\n",
      "  Downloading ruff-0.4.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (24 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio->llama-recipes)\n",
      "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting tomlkit==0.12.0 (from gradio->llama-recipes)\n",
      "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting typer<1.0,>=0.12 (from gradio->llama-recipes)\n",
      "  Downloading typer-0.12.3-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting urllib3~=2.0 (from gradio->llama-recipes)\n",
      "  Downloading urllib3-2.2.1-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting uvicorn>=0.14.0 (from gradio->llama-recipes)\n",
      "  Downloading uvicorn-0.30.1-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting websockets<12.0,>=10.0 (from gradio-client==0.17.0->gradio->llama-recipes)\n",
      "  Downloading websockets-11.0.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from matplotlib->llama-recipes) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from matplotlib->llama-recipes) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from matplotlib->llama-recipes) (4.50.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from matplotlib->llama-recipes) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from matplotlib->llama-recipes) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from matplotlib->llama-recipes) (2.8.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from openai->llama-recipes) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from openai->llama-recipes) (1.9.0)\n",
      "Requirement already satisfied: sniffio in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from openai->llama-recipes) (1.3.1)\n",
      "Collecting coloredlogs (from optimum->llama-recipes)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting texttable (from py7zr->llama-recipes)\n",
      "  Downloading texttable-1.7.0-py2.py3-none-any.whl.metadata (9.8 kB)\n",
      "Collecting pycryptodomex>=3.16.0 (from py7zr->llama-recipes)\n",
      "  Downloading pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
      "Collecting pyzstd>=0.15.9 (from py7zr->llama-recipes)\n",
      "  Downloading pyzstd-0.16.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.4 kB)\n",
      "Collecting pyppmd<1.2.0,>=1.1.0 (from py7zr->llama-recipes)\n",
      "  Downloading pyppmd-1.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.7 kB)\n",
      "Collecting pybcj<1.1.0,>=1.0.0 (from py7zr->llama-recipes)\n",
      "  Downloading pybcj-1.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Collecting multivolumefile>=0.2.3 (from py7zr->llama-recipes)\n",
      "  Downloading multivolumefile-0.2.3-py3-none-any.whl.metadata (6.3 kB)\n",
      "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='developer.download.nvidia.com', port=443): Read timed out. (read timeout=15)\")': /compute/redist/inflate64/\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting inflate64<1.1.0,>=1.0.0 (from py7zr->llama-recipes)\n",
      "  Downloading inflate64-1.0.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Collecting brotli>=1.1.0 (from py7zr->llama-recipes)\n",
      "  Downloading Brotli-1.1.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting jsonschema>=3.0 (from altair<6.0,>=4.2.0->gradio->llama-recipes)\n",
      "  Downloading jsonschema-4.22.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting toolz (from altair<6.0,>=4.2.0->gradio->llama-recipes)\n",
      "  Downloading toolz-0.12.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: idna>=2.8 in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai->llama-recipes) (3.4)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai->llama-recipes) (1.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from aiohttp->datasets->llama-recipes) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from aiohttp->datasets->llama-recipes) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from aiohttp->datasets->llama-recipes) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from aiohttp->datasets->llama-recipes) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from aiohttp->datasets->llama-recipes) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from aiohttp->datasets->llama-recipes) (4.0.3)\n",
      "Requirement already satisfied: certifi in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from httpx>=0.24.1->gradio->llama-recipes) (2022.12.7)\n",
      "Requirement already satisfied: httpcore==1.* in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from httpx>=0.24.1->gradio->llama-recipes) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from httpcore==1.*->httpx>=0.24.1->gradio->llama-recipes) (0.14.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from importlib-resources<7.0,>=1.3->gradio->llama-recipes) (3.11.0)\n",
      "Requirement already satisfied: backcall in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from ipython>=7.8.0->black[jupyter]->llama-recipes) (0.2.0)\n",
      "Requirement already satisfied: decorator in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from ipython>=7.8.0->black[jupyter]->llama-recipes) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from ipython>=7.8.0->black[jupyter]->llama-recipes) (0.18.1)\n",
      "Requirement already satisfied: matplotlib-inline in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from ipython>=7.8.0->black[jupyter]->llama-recipes) (0.1.6)\n",
      "Requirement already satisfied: pickleshare in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from ipython>=7.8.0->black[jupyter]->llama-recipes) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from ipython>=7.8.0->black[jupyter]->llama-recipes) (3.0.36)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from ipython>=7.8.0->black[jupyter]->llama-recipes) (2.15.1)\n",
      "Requirement already satisfied: stack-data in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from ipython>=7.8.0->black[jupyter]->llama-recipes) (0.2.0)\n",
      "Requirement already satisfied: traitlets>=5 in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from ipython>=7.8.0->black[jupyter]->llama-recipes) (5.7.1)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from ipython>=7.8.0->black[jupyter]->llama-recipes) (4.8.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from pandas->datasets->llama-recipes) (2023.4)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from pandas->datasets->llama-recipes) (2024.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from pydantic>=2.0->gradio->llama-recipes) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from pydantic>=2.0->gradio->llama-recipes) (2.18.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from requests->transformers>=4.40.0->llama-recipes) (2.1.1)\n",
      "INFO: pip is looking at multiple versions of requests to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting requests (from transformers>=4.40.0->llama-recipes)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: protobuf in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from transformers[sentencepiece]<4.42.0,>=4.26.0->optimum->llama-recipes) (5.26.0)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0,>=0.12->gradio->llama-recipes)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: rich>=10.11.0 in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from typer<1.0,>=0.12->gradio->llama-recipes) (13.4.2)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->optimum->llama-recipes)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting starlette<0.38.0,>=0.37.2 (from fastapi->gradio->llama-recipes)\n",
      "  Downloading starlette-0.37.2-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting fastapi-cli>=0.0.2 (from fastapi->gradio->llama-recipes)\n",
      "  Downloading fastapi_cli-0.0.4-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 (from fastapi->gradio->llama-recipes)\n",
      "  Downloading ujson-5.10.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.3 kB)\n",
      "Collecting email_validator>=2.0.0 (from fastapi->gradio->llama-recipes)\n",
      "  Downloading email_validator-2.1.1-py3-none-any.whl.metadata (26 kB)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from sympy->torch>=2.2->llama-recipes) (1.3.0)\n",
      "Collecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi->gradio->llama-recipes)\n",
      "  Downloading dnspython-2.6.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from jedi>=0.16->ipython>=7.8.0->black[jupyter]->llama-recipes) (0.8.3)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->llama-recipes)\n",
      "  Downloading jsonschema_specifications-2023.12.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->llama-recipes)\n",
      "  Downloading referencing-0.35.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->llama-recipes)\n",
      "  Downloading rpds_py-0.18.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from pexpect>4.3->ipython>=7.8.0->black[jupyter]->llama-recipes) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=7.8.0->black[jupyter]->llama-recipes) (0.2.13)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio->llama-recipes) (3.0.0)\n",
      "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.12.0->fastapi->gradio->llama-recipes)\n",
      "  Downloading httptools-0.6.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Collecting python-dotenv>=0.13 (from uvicorn[standard]>=0.12.0->fastapi->gradio->llama-recipes)\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.12.0->fastapi->gradio->llama-recipes)\n",
      "  Downloading uvloop-0.19.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.12.0->fastapi->gradio->llama-recipes)\n",
      "  Downloading watchfiles-0.22.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: executing in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from stack-data->ipython>=7.8.0->black[jupyter]->llama-recipes) (0.8.3)\n",
      "Requirement already satisfied: asttokens in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from stack-data->ipython>=7.8.0->black[jupyter]->llama-recipes) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from stack-data->ipython>=7.8.0->black[jupyter]->llama-recipes) (0.2.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio->llama-recipes) (0.1.2)\n",
      "Downloading llama_recipes-0.0.2-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
      "Downloading torch-2.3.0-cp39-cp39-manylinux1_x86_64.whl (779.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m75.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m77.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading triton-2.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m75.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.41.2-py3-none-any.whl (9.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m75.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl (119.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m77.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading black-24.4.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m247.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.4/199.4 kB\u001b[0m \u001b[31m262.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading gradio-4.32.2-py3-none-any.whl (12.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m65.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading gradio_client-0.17.0-py3-none-any.whl (316 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.3/316.3 kB\u001b[0m \u001b[31m275.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
      "Downloading loralib-0.1.2-py3-none-any.whl (10 kB)\n",
      "Downloading optimum-1.20.0-py3-none-any.whl (418 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m418.4/418.4 kB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading peft-0.11.1-py3-none-any.whl (251 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.6/251.6 kB\u001b[0m \u001b[31m293.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading py7zr-0.21.0-py3-none-any.whl (67 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m221.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading altair-5.3.0-py3-none-any.whl (857 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m857.8/857.8 kB\u001b[0m \u001b[31m299.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading Brotli-1.1.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (2.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m156.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.23.2-py3-none-any.whl (401 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.7/401.7 kB\u001b[0m \u001b[31m280.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading inflate64-1.0.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (92 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.0/93.0 kB\u001b[0m \u001b[31m260.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\n",
      "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Downloading orjson-3.10.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.3/142.3 kB\u001b[0m \u001b[31m295.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
      "Downloading pybcj-1.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m203.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m250.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyppmd-1.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.8/138.8 kB\u001b[0m \u001b[31m275.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
      "Downloading pyzstd-0.16.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (413 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m413.8/413.8 kB\u001b[0m \u001b[31m173.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m254.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ruff-0.4.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m89.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Downloading tokenize_rt-5.2.0-py2.py3-none-any.whl (5.8 kB)\n",
      "Downloading tokenizers-0.19.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m80.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading typer-0.12.3-py3-none-any.whl (47 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m203.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading urllib3-2.2.1-py3-none-any.whl (121 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.1/121.1 kB\u001b[0m \u001b[31m249.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading uvicorn-0.30.1-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m223.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m182.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fastapi-0.111.0-py3-none-any.whl (91 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m262.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Downloading texttable-1.7.0-py2.py3-none-any.whl (10 kB)\n",
      "Downloading email_validator-2.1.1-py3-none-any.whl (30 kB)\n",
      "Downloading fastapi_cli-0.0.4-py3-none-any.whl (9.5 kB)\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m264.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jsonschema-4.22.0-py3-none-any.whl (88 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.3/88.3 kB\u001b[0m \u001b[31m277.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m221.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ujson-5.10.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m209.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading websockets-11.0.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.7/129.7 kB\u001b[0m \u001b[31m101.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading toolz-0.12.1-py3-none-any.whl (56 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.1/56.1 kB\u001b[0m \u001b[31m245.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m263.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httptools-0.6.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (345 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.2/345.2 kB\u001b[0m \u001b[31m289.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jsonschema_specifications-2023.12.1-py3-none-any.whl (18 kB)\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Downloading referencing-0.35.1-py3-none-any.whl (26 kB)\n",
      "Downloading rpds_py-0.18.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m295.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading uvloop-0.19.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m62.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading watchfiles-0.22.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m281.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: fire, ffmpy\n",
      "  Building wheel for fire (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fire: filename=fire-0.6.0-py2.py3-none-any.whl size=117047 sha256=5268285209d1b77a04fdb57d38e1feb6422780af6c6b5ed5d7633df94acc5bef\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ntnkowip/wheels/ec/ce/ba/9d5764d2266c500c18776c7d8f1e3c023075994cbc6dea47db\n",
      "  Building wheel for ffmpy (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5599 sha256=dea20a6b510919b2edaf110efdfd67afc55c5dbf26a853a3a288a8a9cb7c7c44\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ntnkowip/wheels/fd/f6/eb/b42ef38e0c6298906279494f5fcf10aee4b4bd07346b8f900b\n",
      "Successfully built fire ffmpy\n",
      "Installing collected packages: texttable, pydub, ffmpy, brotli, appdirs, websockets, uvloop, urllib3, ujson, typing-extensions, triton, toolz, tomlkit, tokenize-rt, shellingham, semantic-version, ruff, rpds-py, pyzstd, python-multipart, python-dotenv, pyppmd, pycryptodomex, pybcj, pathspec, orjson, nvidia-nccl-cu12, mypy-extensions, multivolumefile, loralib, inflate64, humanfriendly, httptools, fire, dnspython, chardet, aiofiles, uvicorn, requests, referencing, py7zr, email_validator, coloredlogs, black, watchfiles, typer, torch, starlette, jsonschema-specifications, huggingface-hub, tokenizers, jsonschema, gradio-client, fastapi-cli, bitsandbytes, transformers, fastapi, altair, peft, gradio, optimum, llama-recipes\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.26.13\n",
      "    Uninstalling urllib3-1.26.13:\n",
      "      Successfully uninstalled urllib3-1.26.13\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.10.0\n",
      "    Uninstalling typing_extensions-4.10.0:\n",
      "      Successfully uninstalled typing_extensions-4.10.0\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 2.1.0\n",
      "    Uninstalling triton-2.1.0:\n",
      "      Successfully uninstalled triton-2.1.0\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "    Found existing installation: nvidia-nccl-cu12 2.18.1\n",
      "    Uninstalling nvidia-nccl-cu12-2.18.1:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.18.1\n",
      "\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages/nvidia/~ccl'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.28.2\n",
      "    Uninstalling requests-2.28.2:\n",
      "      Successfully uninstalled requests-2.28.2\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.1.0\n",
      "    Uninstalling torch-2.1.0:\n",
      "      Successfully uninstalled torch-2.1.0\n",
      "\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages/~-rch'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.22.2\n",
      "    Uninstalling huggingface-hub-0.22.2:\n",
      "      Successfully uninstalled huggingface-hub-0.22.2\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.15.2\n",
      "    Uninstalling tokenizers-0.15.2:\n",
      "      Successfully uninstalled tokenizers-0.15.2\n",
      "\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/home/jovyan/.mlspace/envs/bench/lib/python3.9/site-packages/~okenizers'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.39.3\n",
      "    Uninstalling transformers-4.39.3:\n",
      "      Successfully uninstalled transformers-4.39.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "botocore 1.34.82 requires urllib3<1.27,>=1.25.4; python_version < \"3.10\", but you have urllib3 2.2.1 which is incompatible.\n",
      "flair 0.13.1 requires urllib3<2.0.0,>=1.0.0, but you have urllib3 2.2.1 which is incompatible.\n",
      "openxlab 0.0.37 requires requests~=2.28.2, but you have requests 2.32.3 which is incompatible.\n",
      "torchaudio 2.1.0 requires torch==2.1.0, but you have torch 2.3.0 which is incompatible.\n",
      "torchvision 0.16.0 requires torch==2.1.0, but you have torch 2.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed aiofiles-23.2.1 altair-5.3.0 appdirs-1.4.4 bitsandbytes-0.43.1 black-24.4.2 brotli-1.1.0 chardet-5.2.0 coloredlogs-15.0.1 dnspython-2.6.1 email_validator-2.1.1 fastapi-0.111.0 fastapi-cli-0.0.4 ffmpy-0.3.2 fire-0.6.0 gradio-4.32.2 gradio-client-0.17.0 httptools-0.6.1 huggingface-hub-0.23.2 humanfriendly-10.0 inflate64-1.0.0 jsonschema-4.22.0 jsonschema-specifications-2023.12.1 llama-recipes-0.0.2 loralib-0.1.2 multivolumefile-0.2.3 mypy-extensions-1.0.0 nvidia-nccl-cu12-2.20.5 optimum-1.20.0 orjson-3.10.3 pathspec-0.12.1 peft-0.11.1 py7zr-0.21.0 pybcj-1.0.2 pycryptodomex-3.20.0 pydub-0.25.1 pyppmd-1.1.0 python-dotenv-1.0.1 python-multipart-0.0.9 pyzstd-0.16.0 referencing-0.35.1 requests-2.32.3 rpds-py-0.18.1 ruff-0.4.7 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.37.2 texttable-1.7.0 tokenize-rt-5.2.0 tokenizers-0.19.1 tomlkit-0.12.0 toolz-0.12.1 torch-2.3.0 transformers-4.41.2 triton-2.3.0 typer-0.12.3 typing-extensions-4.7.1 ujson-5.10.0 urllib3-2.2.1 uvicorn-0.30.1 uvloop-0.19.0 watchfiles-0.22.0 websockets-11.0.3\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42fe0f33-80f2-486d-8868-acafdfc0a2ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lens = [len(elem) for elem in ds['data']['dialogue_history']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b060e4c0-a3f6-45f3-abf8-333bfbdff709",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Load corresponding entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe43159f-1184-4c5f-acc2-4ec4af3dd293",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('column_with_embs.pkl', 'rb') as f:\n",
    "    column_with_embs = pickle.load(f)\n",
    "\n",
    "with open('column_with_entss.pkl', 'rb') as f:\n",
    "    column_with_entites = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c663178f-5eca-4dac-b9cf-d080ff872a56",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Arthur's Magazine\", 'First for Women']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_with_entites[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68b54fa8-1e15-4947-98f8-383dc7bfdcc2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'column_with_embs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mlen\u001b[39m(\u001b[43mcolumn_with_embs\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'column_with_embs' is not defined"
     ]
    }
   ],
   "source": [
    "len(column_with_embs[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "996ea724-f273-42ff-9b63-922ee40d4ad6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['knowledge', 'question', 'right_answer', 'hallucinated_answer'],\n",
       "    num_rows: 10000\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['data']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309f8bfd-6421-453d-9028-68ac114b455a",
   "metadata": {},
   "source": [
    "## 3 Check accuracy of mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f377f47-03ec-4b33-9b3a-ebfda9515324",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "6000\n",
      "6500\n",
      "7000\n",
      "7500\n",
      "8000\n",
      "8500\n",
      "9000\n",
      "9500\n"
     ]
    }
   ],
   "source": [
    "distances = []\n",
    "\n",
    "for ind, qu in enumerate(ds['data']['question']):\n",
    "    predicted_graph_embedding = text2graph_emb(qu)\n",
    "    distance = [numpy.linalg.norm(predicted_graph_embedding.cpu().numpy() - elem) for elem in column_with_embs[ind] if -111 not in column_with_embs[ind]]\n",
    "    if (len(distance) > 0):\n",
    "        distances.append(min(distance))\n",
    "    if (ind % 500 == 0):\n",
    "        print (ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "065f739c-df92-46f0-af80-ffbd98f70fab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.547851962482012"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.mean(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f7bfda2-957f-4733-8cb3-d62e7ef9c9f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.547851962482012"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.sum(distances)/len(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80d430ce-a344-4b88-84f2-321314d957e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bad_words_ids = tokenizer([\"\\n\", \"</s>\", \":\"], add_special_tokens=False).input_ids\n",
    "\n",
    "gen_params = {\n",
    "        \"do_sample\": False,\n",
    "        \"max_new_tokens\": 40,\n",
    "        \"early_stopping\": True,\n",
    "        \"num_beams\": 3,\n",
    "        \"repetition_penalty\": 1.0,\n",
    "        \"remove_invalid_values\": True,\n",
    "        \"eos_token_id\": 2,\n",
    "        \"pad_token_id\": 2,\n",
    "        \"forced_eos_token_id\": 2,\n",
    "        \"use_cache\": True,\n",
    "        \"no_repeat_ngram_size\": 4,\n",
    "        \"bad_words_ids\": bad_words_ids,\n",
    "        \"num_return_sequences\": 1,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04924025-dc94-4101-a9f7-35ca525dc624",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ask_mistral(model, tokenizer, question):\n",
    "    question_ids = tokenizer.encode(question, add_special_tokens=False, return_tensors=\"pt\").to(device=DEVICE)\n",
    "    question_embeddings = model.model.embed_tokens(question_ids).to(torch.bfloat16)\n",
    "    out = model.generate(inputs_embeds=question_embeddings, **gen_params)\n",
    "    out = out[:, 1:]\n",
    "    generated_texts = tokenizer.batch_decode(out)[0]\n",
    "    return generated_texts\n",
    "\n",
    "def ask_mistral_with_assist_prompt(model, tokenizer, question):\n",
    "    PROMPT = \"This is a dialog with AI assistant.\\n\"\n",
    "    prompt_ids = tokenizer.encode(f\"{PROMPT}\", add_special_tokens=False, return_tensors=\"pt\").to(device=DEVICE)\n",
    "    prompt_embeddings = model.model.embed_tokens(prompt_ids).to(torch.bfloat16)\n",
    "    question_ids = tokenizer.encode(question, add_special_tokens=False, return_tensors=\"pt\").to(device=DEVICE)\n",
    "    question_embeddings = model.model.embed_tokens(question_ids).to(torch.bfloat16)\n",
    "    embeddings = torch.cat(\n",
    "            [\n",
    "                prompt_embeddings,\n",
    "                question_embeddings,\n",
    "            ],\n",
    "            dim=1,\n",
    "        ).to(dtype=torch.bfloat16, device=DEVICE)\n",
    "    out = model.generate(inputs_embeds=embeddings, **gen_params)\n",
    "    out = out[:, 1:]\n",
    "    generated_texts = tokenizer.batch_decode(out)[0]\n",
    "    return generated_texts\n",
    "\n",
    "\n",
    "def ask_mistral_with_kg_embeddings(model, tokenizer, question):\n",
    "    PROMPT = \"This is a dialog with AI assistant.\\n\"\n",
    "    prompt_ids = tokenizer.encode(f\"{PROMPT}\", add_special_tokens=False, return_tensors=\"pt\").to(device=DEVICE)\n",
    "    prompt_embeddings = model.model.embed_tokens(prompt_ids).to(torch.bfloat16)\n",
    "    question_ids = tokenizer.encode(question, add_special_tokens=False, return_tensors=\"pt\").to(device=DEVICE)\n",
    "    question_embeddings = model.model.embed_tokens(question_ids).to(torch.bfloat16)\n",
    "    ent_embs = text2graph_emb(text).to(torch.bfloat16)\n",
    "    try:\n",
    "        #ent_embs = torch.tensor(ent_embs).to(device=DEVICE, dtype=model.dtype)\n",
    "        m = ent_embs.mean(1, keepdim=True)\n",
    "        s = ent_embs.std(1, unbiased=False, keepdim=True)\n",
    "        ent_embs -= m\n",
    "        ent_embs /= s\n",
    "    except:\n",
    "        print (ent_embs.shape)\n",
    "    projected_kg_embeddings = projection(ent_embs[:,None,:])\n",
    "    #print (question_embeddings.shape, start_emb[None, None, ...].shape, projected_kg_embeddings.shape)\n",
    "    embeddings = torch.cat(\n",
    "               [\n",
    "                    prompt_embeddings,\n",
    "                    question_embeddings,\n",
    "                    start_emb[None, None, ...],\n",
    "                    projected_kg_embeddings,\n",
    "                    end_emb[None, None, ...]\n",
    "                ],\n",
    "            dim=1,\n",
    "        ).to(dtype=torch.bfloat16, device=DEVICE)\n",
    "    out = model.generate(inputs_embeds=embeddings, **gen_params)\n",
    "    out = out[:, 1:]\n",
    "    generated_texts = tokenizer.batch_decode(out)[0]\n",
    "    return generated_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fac016c-ec92-4a87-a1e5-0ffda0130eb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('column_with_embs.pkl', 'rb') as f:\n",
    "    column_with_embs = pickle.load(f)\n",
    "\n",
    "with open('column_with_entss.pkl', 'rb') as f:\n",
    "    column_with_entites = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4f67788-155c-465c-919e-d9cd504090fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "0\n",
      "Which magazine was started first Arthur's Magazine or First for Women?\n",
      "Mistral answer:   for Women was started first. Arthur's Magazine was started in 1989, while First for Women magazine was started in the 1970s. First for Women</s>\n",
      "Real answer:  Arthur's Magazine\n",
      "hallucinated_answer First for Women was started first.\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "The Oberoi family is part of a hotel company that has a head office in what city?\n",
      "Mistral answer:   Delhi, India. The Oberoi Group of Hotels is a luxury hotel chain based in India. The company was founded in 1934 by Mohan Singh Oberoi and his</s>\n",
      "Real answer:  Delhi\n",
      "hallucinated_answer The Oberoi family's hotel company is based in Mumbai.\n",
      "\n",
      "\n",
      "\n",
      "2\n",
      "Musician and satirist Allie Goertz wrote a song about the \"The Simpsons\" character Milhouse, who Matt Groening named after who?\n",
      "Mistral answer:   house Van Houten is a fictional character in the American animated television series The Simpsons. He is the best friend of Bart Simpson. He is voiced by Pamela</s>\n",
      "Real answer:  President Richard Nixon\n",
      "hallucinated_answer Allie Goertz wrote a song about Milhouse, a popular TV character, named after an influential political figure.\n",
      "\n",
      "\n",
      "\n",
      "3\n",
      " What nationality was James Henry Miller's wife?\n",
      "Mistral answer:   . James Henry Miller's wife was an American citizen. She was born and raised in the United States, and she met James Henry Miller while he was working as a diplomat in the</s>\n",
      "Real answer:  American\n",
      "hallucinated_answer James Henry Miller's wife was British.\n",
      "\n",
      "\n",
      "\n",
      "4\n",
      "Cadmium Chloride is slightly soluble in this chemical, it is also called what?\n",
      "Mistral answer:   dCl2 · 2.5 H2O or cadmium chloride dihydrate. It is a white crystalline solid that is soluble in water</s>\n",
      "Real answer:  alcohol\n",
      "hallucinated_answer water with a hint of alcohol\n",
      "\n",
      "\n",
      "\n",
      "5\n",
      "Which tennis player won more Grand Slam titles, Henri Leconte or Jonathan Stark?\n",
      "Mistral answer:   Leconte won more Grand Slam titles than Jonathan Stark. Leconte is a French former professional tennis player who won 11 Grand Slam doubles titles, while St</s>\n",
      "Real answer:  Jonathan Stark\n",
      "hallucinated_answer Henri Leconte won more Grand Slam titles.\n",
      "\n",
      "\n",
      "\n",
      "6\n",
      "Which genus of moth in the world's seventh-largest country contains only one species?\n",
      "Mistral answer:   epidoptera. The genus is known as *Eupithecia* and the species is *E. pallidata*. *E. Pallidata* is</s>\n",
      "Real answer:  Crambidae\n",
      "hallucinated_answer The Indogrammodes genus of moths found in India has only one species.\n",
      "\n",
      "\n",
      "\n",
      "7\n",
      "Who was once considered the best kick boxer in the world, however he has been involved in a number of controversies relating to his \"unsportsmanlike conducts\" in the sport and crimes of violence outside of the ring.\n",
      "Mistral answer:   \"The Dragon\" Wilson Jr. is an American martial artist, actor, and former professional kickboxer. He is a six-time world kickboxing champion and a two-</s>\n",
      "Real answer:  Badr Hari\n",
      "hallucinated_answer Badr Hari is a notorious kickboxer.\n",
      "\n",
      "\n",
      "\n",
      "8\n",
      "The Dutch-Belgian television series that \"House of Anubis\" was based on first aired in what year?\n",
      "Mistral answer:   2008–2012. \"House of Anubis\" is an American teen drama television series that aired on Nickelodeon from December 1,</s>\n",
      "Real answer:  2006\n",
      "hallucinated_answer The inspiration for \"House of Anubis\" first aired in 2003.\n",
      "\n",
      "\n",
      "\n",
      "9\n",
      "What is the length of the track where the 2013 Liqui Moly Bathurst 12 Hour was staged?\n",
      "Mistral answer:   6.213 kilometres (3.861 mi) long. The track is 6.172 km long, with a 0.041 km long</s>\n",
      "Real answer:  6.213 km long\n",
      "hallucinated_answer The Mount Panorama Circuit track is longer than 7 km.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "for ind, elem in enumerate(ds['data']):\n",
    "    if (ind < 10):\n",
    "        question = elem['question']\n",
    "        #ents = column_with_entites[ind]\n",
    "        #embs = np.array([elem for elem in column_with_embs[ind] if elem != -111])\n",
    "        emb = text2graph_emb(question)[0].cpu().numpy()\n",
    "        \n",
    "        answ = ask_mistral_with_kg_embeddings(model, tokenizer, question)\n",
    "        #if (ds['data']['right_answer'][ind] in answ or ind == 0):\n",
    "        print (\"\\n\\n\")\n",
    "        print (ind)\n",
    "        print (question)\n",
    "        #print (ents)\n",
    "        print (\"Mistral answer: \", ask_mistral_with_kg_embeddings(model, tokenizer, question))\n",
    "        print (\"Real answer: \", ds['data']['right_answer'][ind])\n",
    "        print (\"hallucinated_answer\", ds['data']['hallucinated_answer'][ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5d5964-0a1d-444e-b7cd-179bb47596d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ask_mistral(model, tokenizer, \"What nationality was James Henry Miller's wife?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106099d7-0a21-44e7-9b8f-a9fdc516b2d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ask_mistral(model, tokenizer, \"Which tennis player won more Grand Slam titles, Henri Leconte or Jonathan Stark?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87ecf63-5dbb-4fe5-b0a7-92e6d2cba1d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ask_mistral(model, tokenizer, \"What body of water does Suggan Buggan River join?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d620663-d678-453e-86d0-674afeae7efb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ask_mistral(model, tokenizer, \"What team is Nicolas Raffault associated with?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1015ed7-9f39-4d5d-b6fb-1a4040b8881a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ask_mistral(model, tokenizer, \"What is the length of the track where the 2013 Liqui Moly Bathurst 12 Hour was staged?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8f0cd1-fb3a-480b-aba7-ce30733641cf",
   "metadata": {},
   "source": [
    "## Simple "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d41f844b-43a0-4cff-8cd8-80ee303c767c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  Which magazine was started first Arthur's Magazine or First for Women?\n",
      "Mistral answer:   for Women was started first. Arthur's Magazine was started in 1989, while First for Women magazine was started in the 1970s. First for Women</s>\n",
      "Real answer:  Arthur's Magazine\n",
      "hallucinated_answer First for Women was started first.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Question:  Which band was founded first, Hole, the rock band that Courtney Love was a frontwoman of, or The Wolfhounds?\n",
      "Mistral answer:   Wolfhounds. Hole was formed in 1989 by Courtney Love and Eric Erlandson in Los Angeles, California. The band's name was inspired by the</s>\n",
      "Real answer:  The Wolfhounds\n",
      "hallucinated_answer Hole, the rock band that Courtney Love was a frontwoman of was founded first.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Question:  Were Pavel Urysohn and Leonid Levin known for the same type of work?\n",
      "Mistral answer:   , they were not known for the same type of work. Pavel Urysohn was a Russian mathematician known for his work in topology, while Leonid Levin</s>\n",
      "Real answer:  no\n",
      "hallucinated_answer Pavel Urysohn and Leonid Levin collaborated on mathematical research.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Question:  Are both The New Pornographers and Kings of Leon American rock bands?\n",
      "Mistral answer:   and yes. The New Pornographers are a Canadian indie rock band formed in Vancouver, British Columbia, in 1997. Kings of Leon are an American rock band</s>\n",
      "Real answer:  no\n",
      "hallucinated_answer Yes, both The New Pornographers and Kings of Leon are now American rock bands.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Question:  750 7th Avenue and 101 Park Avenue, are located in which city?\n",
      "Mistral answer:   York City, New York, United States of America. 750 7th Avenue and 101 Park Avenue are both located in the Midtown Manhattan neighborhood of New York</s>\n",
      "Real answer:  New York City\n",
      "hallucinated_answer 750 7th Avenue and 101 Park Avenue are located in Albany, New York.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Question:  Which actress played the part of fictitious character Kimberly Ann Hart, in the franchise built around a live action superhero television series taking much of its footage from the Japanese tokusatsu 'Super Sentai'?\n",
      "Mistral answer:   Jo Johnson. Amy Jo Johnson is a Canadian actress and musician. She is best known for her role as Kimberly Hart, the Pink Ranger, in Mighty Morphin Power</s>\n",
      "Real answer:  Amy Jo Johnson\n",
      "hallucinated_answer Kimberly was played by Amy Johnson.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Question:  What profession does Nicholas Ray and Elia Kazan have in common?\n",
      "Mistral answer:   and screenwriter. Both Nicholas Ray and Elia Kazan are American film directors and screenwriters who have made significant contributions to the film industry. Ray is known for his work on films</s>\n",
      "Real answer:  director\n",
      "hallucinated_answer Nicholas Ray and Elia Kazan both worked in the film industry.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Question:  Which documentary is about Finnish rock groups, Adam Clayton Powell or The Saimaa Gesture?\n",
      "Mistral answer:   Saimaa Gesture is a 2007 Finnish documentary film about the Finnish rock group Hanoi Rocks. The film was directed by Jukka Kär</s>\n",
      "Real answer:  The Saimaa Gesture\n",
      "hallucinated_answer Adam Clayton Powell is about civil rights leader.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Question:  The American Pre-Code comedy film featuring an American actress, dancer, and singer, widely known for performing in films and RKO's musical films, was released in what year?\n",
      "Mistral answer:   1933. \"42nd Street\" is an American Pre-Code comedy film featuring an American actress, dancer, and singer, widely known for performing in films and R</s>\n",
      "Real answer:  1932\n",
      "hallucinated_answer The film was released in 1938.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Question:  Which band has more members, Saint Motel or Curve?\n",
      "Mistral answer:   Motel. Saint Motel is an American indie rock band from Los Angeles, California, formed in 2007. The band consists of A/J Jackson (voc</s>\n",
      "Real answer:  Saint Motel\n",
      "hallucinated_answer Curve has no more members.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Question:  What city are George Washington University Hospital and MedStar Washington Hospital Center located in?\n",
      "Mistral answer:   , D.C. in the United States. George Washington University Hospital and MedStar Washington Hospital Center are both located in the Foggy Bottom neighborhood of Washington, D..C.</s>\n",
      "Real answer:  Washington, D.C.\n",
      "hallucinated_answer The George Washington University Hospital and MedStar Washington Hospital Center are located in different cities.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Question:  Who performed the lead single on the album Friends in Low Places, No Fences, that reached #1 on Billboard?\n",
      "Mistral answer:   arth Brooks. \"Friends in Low Places\" is a song written by Dean Dillon and Earl Bud Lee. It was originally recorded by American country music singer-songwriter</s>\n",
      "Real answer:  Garth Brooks\n",
      "hallucinated_answer \"Friends in Low Places\" was performed by Brooks Garth.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Question:  What year was the winner of the 2016 Marrakesh ePrix born?\n",
      "Mistral answer:   1986. The winner of the 2016 Marrakesh ePrix was Sébastien Buemi, a Swiss racing driver who was born in 1</s>\n",
      "Real answer:  1988\n",
      "hallucinated_answer Sébastien Buemi was born in 1988.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Question:  South Korean actor Kim Yool-ho starred in what 2016 movie directed by Yeon Sang-ho Yeon Sang-ho and starring actors Gong Yoo, Jung Yu-mi, and Ma Dong-seok?\n",
      "Mistral answer:   to Busan (2016) is a South Korean zombie horror film directed by Yeon Sang-ho and starring Gong Yoo, Jung Yu-mi,</s>\n",
      "Real answer:  Train to Busan\n",
      "hallucinated_answer Kim Yool-ho starred in another South Korean zombie movie directed by Yeon Sang-ho, which starred Gong Yoo, Jung Yu-mi, and Ma Dong-seok called \"Peninsula\".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Question:  In which stadium do the teams owned by Myra Kraft's husband play?\n",
      "Mistral answer:   lette Stadium in Foxborough, Massachusetts, United States. The stadium is the home of the New England Patriots of the National Football League (NFL) and the New England Revolution of Major</s>\n",
      "Real answer:  Gillette Stadium\n",
      "hallucinated_answer Myra Hiatt Kraft's husband owned a stadium.\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for ind, elem in enumerate(ds['data']['question']):\n",
    "    if (ind in [0, 22, 27, 28,29, 30, 33, 35, 58, 60, 74, 79, 82, 83, 90]):\n",
    "        print (\"Question: \", elem)\n",
    "        print (\"Mistral answer: \", ask_mistral_with_kg_embeddings(model, tokenizer,elem))\n",
    "        print (\"Real answer: \", ds['data']['right_answer'][ind])\n",
    "        print (\"hallucinated_answer\", ds['data']['hallucinated_answer'][ind])\n",
    "        print (\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555b612c-7828-46f0-9b13-a52794be237b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind, elem in enumerate(ds['data']['question'][:10]):\n",
    "    print (\"Question: \", elem)\n",
    "    print (\"Mistral answer: \", ask_mistral_with_assist_prompt(model, tokenizer,elem))\n",
    "    print (\"Real answer: \", ds['data']['right_answer'][ind])\n",
    "    print (\"hallucinated_answer\", ds['data']['hallucinated_answer'][ind])\n",
    "    print (\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6f8176-9342-408d-8f3e-5774e3104d15",
   "metadata": {},
   "source": [
    "## Strong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68ee3d5-dadd-47ed-9fd7-b2d245caf452",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('benchmark_ZsRE_ZsRE-test-all.json') as f:\n",
    "    a = json.load(f)\n",
    "    #line_content = [json.loads(line) for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b431c9e-0512-4e8f-b4b8-07220464479f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e717618b-7fe5-4c20-b886-2a677b087b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind, elem in enumerate(a[:10]):\n",
    "    print (\"Question: \", elem['prompt'])\n",
    "    print (\"Mistral answer: \", ask_mistral_with_assist_prompt(model, tokenizer,elem['prompt']))\n",
    "    print (\"\\n\\n\")\n",
    "    print (\"Real answer: \", elem['ground_truth'])\n",
    "    print (\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc88bed7-22c6-4d68-9a2c-e484becdb80d",
   "metadata": {},
   "source": [
    "# Count accuracy and f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1926ee-ef59-40a5-9898-9944ad94efcc",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fa65e6-f404-4e60-b778-1e6e047597ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n"
     ]
    }
   ],
   "source": [
    "tr_pos = 0\n",
    "\n",
    "for ind, elem in enumerate(ds['data']['question']):\n",
    "    if (ind % 100==0):\n",
    "        print (ind)\n",
    "    answ = ask_mistral_with_kg_embeddings(model, tokenizer,elem)\n",
    "    if ds['data']['right_answer'][ind] in answ:\n",
    "        tr_pos += 1\n",
    "\n",
    "print (tr_pos / 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d60013dc-2d84-44d9-9b7a-c3107b971a45",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tr_pos' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[43mtr_pos\u001b[49m \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m10000\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tr_pos' is not defined"
     ]
    }
   ],
   "source": [
    "print (tr_pos / 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "804aac6e-cb7f-4cfa-889b-74aacd59f637",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "tr_pos = 0\n",
    "\n",
    "for ind, elem in enumerate(ds['data']['question']):\n",
    "    if (ind % 1000==0):\n",
    "        print (ind, flush=True)\n",
    "    ents = column_with_entites[ind]\n",
    "    embs = np.array([elem for elem in column_with_embs[ind] if elem != -111])\n",
    "    answ = ds['data']['right_answer'][ind]\n",
    "    if ds['data']['right_answer'][ind] in answ:\n",
    "        tr_pos += 1\n",
    "\n",
    "print (tr_pos / 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccd75a0-3266-4472-ad60-59032dba873e",
   "metadata": {},
   "source": [
    "### F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3cc732ea-298e-4cc7-8dcf-a4ff3818e764",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "#import ujson as json\n",
    "import re\n",
    "import string\n",
    "from collections import Counter\n",
    "import pickle\n",
    "\n",
    "def normalize_answer(s):\n",
    "\n",
    "    def remove_articles(text):\n",
    "        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
    "\n",
    "    def white_space_fix(text):\n",
    "        return ' '.join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return ''.join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
    "\n",
    "\n",
    "def f1_score(prediction, ground_truth):\n",
    "    normalized_prediction = normalize_answer(prediction)\n",
    "    normalized_ground_truth = normalize_answer(ground_truth)\n",
    "\n",
    "    ZERO_METRIC = (0, 0, 0)\n",
    "\n",
    "    if normalized_prediction in ['yes', 'no', 'noanswer'] and normalized_prediction != normalized_ground_truth:\n",
    "        return ZERO_METRIC\n",
    "    if normalized_ground_truth in ['yes', 'no', 'noanswer'] and normalized_prediction != normalized_ground_truth:\n",
    "        return ZERO_METRIC\n",
    "\n",
    "    prediction_tokens = normalized_prediction.split()\n",
    "    ground_truth_tokens = normalized_ground_truth.split()\n",
    "    common = Counter(prediction_tokens) & Counter(ground_truth_tokens)\n",
    "    num_same = sum(common.values())\n",
    "    if num_same == 0:\n",
    "        return ZERO_METRIC\n",
    "    precision = 1.0 * num_same / len(prediction_tokens)\n",
    "    recall = 1.0 * num_same / len(ground_truth_tokens)\n",
    "    f1 = (2 * precision * recall) / (precision + recall)\n",
    "    return f1, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a42b489-b5dd-4c6c-a6a8-93765f1dff41",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(column_with_entites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c157f8d-2dc2-46d2-b862-4531b3d36dfd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "metrics = []\n",
    "import numpy as np\n",
    "for ind, elem in enumerate(ds['data']['question']):\n",
    "    if (ind % 1000==0):\n",
    "        print (ind, flush=True)\n",
    "    ents = column_with_entites[ind]\n",
    "    embs = np.array([elem for elem in column_with_embs[ind] if elem != -111])\n",
    "    try:\n",
    "        answ = ask_mistral_with_kg_embeddings(model, tokenizer, elem)\n",
    "    except:\n",
    "        print (embs.shape)\n",
    "        answ = ask_mistral_with_assist_prompt(model, tokenizer, elem)\n",
    "    metrics.append(f1_score(answ, ds['data']['right_answer'][ind]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510a8f6c-a1f5-41ec-91c9-7d1d31ff7def",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61335539-59b9-4f69-bed0-f2494e27b895",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0151b58f-88c4-4ed0-80a6-7926fca77015",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a, b, c = zip(*metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6eeae571-f6e9-493d-b71d-f909cfcd7621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05251545056040395 0.030653166741687256 0.249612946241022\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print (np.mean(a), np.mean(b), np.mean(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "651e1dd7-ccbb-48b5-8405-db4486895697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07774725687776247 0.045892641806880546 0.3427478656863656\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print (np.mean(a), np.mean(b), np.mean(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49350c80-7a85-4d87-8d49-c8ebd54d4a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print (np.mean(a), np.mean(b), np.mean(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46595025-bfcc-453e-a101-2b9c10b2e537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting evaluate\n",
      "  Using cached evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
      "Collecting responses<0.19\n",
      "  Using cached responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: multiprocess in /home/jovyan/.imgenv-chekalina-long-context-3-0/lib/python3.9/site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/user/conda/lib/python3.9/site-packages (from evaluate) (4.64.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /home/jovyan/.imgenv-chekalina-long-context-3-0/lib/python3.9/site-packages (from evaluate) (0.21.4)\n",
      "Requirement already satisfied: xxhash in /home/jovyan/.imgenv-chekalina-long-context-3-0/lib/python3.9/site-packages (from evaluate) (3.4.1)\n",
      "Requirement already satisfied: pandas in /home/user/conda/lib/python3.9/site-packages (from evaluate) (1.5.3)\n",
      "Requirement already satisfied: dill in /home/jovyan/.imgenv-chekalina-long-context-3-0/lib/python3.9/site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: packaging in /home/user/conda/lib/python3.9/site-packages (from evaluate) (22.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/user/conda/lib/python3.9/site-packages (from evaluate) (2.28.2)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /home/jovyan/.imgenv-chekalina-long-context-3-0/lib/python3.9/site-packages (from evaluate) (2024.2.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/user/conda/lib/python3.9/site-packages (from evaluate) (1.23.5)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /home/jovyan/.imgenv-chekalina-long-context-3-0/lib/python3.9/site-packages (from evaluate) (2.18.0)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /home/jovyan/.imgenv-chekalina-long-context-3-0/lib/python3.9/site-packages (from datasets>=2.0.0->evaluate) (15.0.1)\n",
      "Requirement already satisfied: filelock in /home/user/conda/lib/python3.9/site-packages (from datasets>=2.0.0->evaluate) (3.9.0)\n",
      "Requirement already satisfied: aiohttp in /home/user/conda/lib/python3.9/site-packages (from datasets>=2.0.0->evaluate) (3.8.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/user/conda/lib/python3.9/site-packages (from datasets>=2.0.0->evaluate) (6.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /home/jovyan/.imgenv-chekalina-long-context-3-0/lib/python3.9/site-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/user/conda/lib/python3.9/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/user/conda/lib/python3.9/site-packages (from requests>=2.19.0->evaluate) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/user/conda/lib/python3.9/site-packages (from requests>=2.19.0->evaluate) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/user/conda/lib/python3.9/site-packages (from requests>=2.19.0->evaluate) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/user/conda/lib/python3.9/site-packages (from requests>=2.19.0->evaluate) (3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/user/conda/lib/python3.9/site-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/user/conda/lib/python3.9/site-packages (from pandas->evaluate) (2022.7.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/user/conda/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/user/conda/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/user/conda/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/user/conda/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.8.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/user/conda/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/user/conda/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (22.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/user/conda/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n",
      "Installing collected packages: responses, evaluate\n",
      "Successfully installed evaluate-0.4.1 responses-0.18.0\n"
     ]
    }
   ],
   "source": [
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b572e858-0261-44ca-81ea-aac8a219e83e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Mismatch in the number of predictions (1) and references (4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m refs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe cat\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtheater\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYELLING\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124magent007\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      5\u001b[0m preds \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcat?\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m----> 6\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mexact_match\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreferences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrefs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregexes_to_ignore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthe \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43myell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYELL\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_case\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_punctuation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_numbers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.imgenv-chekalina-long-context-3-0/lib/python3.9/site-packages/evaluate/module.py:450\u001b[0m, in \u001b[0;36mEvaluationModule.compute\u001b[0;34m(self, predictions, references, **kwargs)\u001b[0m\n\u001b[1;32m    447\u001b[0m compute_kwargs \u001b[38;5;241m=\u001b[39m {k: kwargs[k] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m kwargs \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_feature_names()}\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[0;32m--> 450\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_finalize()\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_file_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.imgenv-chekalina-long-context-3-0/lib/python3.9/site-packages/evaluate/module.py:541\u001b[0m, in \u001b[0;36mEvaluationModule.add_batch\u001b[0;34m(self, predictions, references, **kwargs)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    535\u001b[0m     error_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    536\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredictions and/or references don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt match the expected format.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    537\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected format: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mselected_feature_format\u001b[38;5;250m \u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    538\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput predictions: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msummarize_if_long_list(predictions)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    539\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput references: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msummarize_if_long_list(references)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    540\u001b[0m     )\n\u001b[0;32m--> 541\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(error_msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: Mismatch in the number of predictions (1) and references (4)"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "exact_match_metric = load(\"exact_match\")\n",
    "exact_match = evaluate.load(\"exact_match\")\n",
    "refs = [\"the cat\", \"theater\", \"YELLING\", \"agent007\"]\n",
    "preds = [\"cat?\"]\n",
    "results = exact_match.compute(references=refs, predictions=preds, regexes_to_ignore=[\"the \", \"yell\", \"YELL\"], ignore_case=True, ignore_punctuation=True, ignore_numbers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ece47a8-6ee4-4384-943b-00ad6b06ea14",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd00d58c-b662-4900-a5b0-109e04cbdfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_hpqa = load_dataset('hotpot_qa', 'distractor')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e48a2e-6a2c-4dfd-93d2-bfd06551caa2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.mlspace-bench]",
   "language": "python",
   "name": "conda-env-.mlspace-bench-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

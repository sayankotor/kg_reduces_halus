{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51f5a1e2-3069-4e4f-b972-ca67e249d6bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "libgomp: Invalid value for environment variable OMP_NUM_THREADS\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5232923cbfde4bb2ac4790230e52ab6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46152695248f43b1a262bcdf39d6d095",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/conda/lib/python3.9/site-packages/torch/_utils.py:771: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of embeddings in tokenizer: 32000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from urllib.request import urlopen\n",
    "import torch.nn as nn\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Loading some sources of the projection adapter and image encoder\n",
    "hf_hub_download(repo_id=\"AIRI-Institute/OmniFusion\", filename=\"models.py\", local_dir='./')\n",
    "from models import CLIPVisionTower\n",
    "\n",
    "DEVICE = \"cuda:1\"\n",
    "PROMPT = \"This is a dialog with AI assistant.\\n\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"AIRI-Institute/OmniFusion\", subfolder=\"OmniMistral-tokenizer\", use_fast=False)\n",
    "model = AutoModelForCausalLM.from_pretrained(\"AIRI-Institute/OmniFusion\", subfolder=\"OmniMistral-model\", torch_dtype=torch.bfloat16, device_map=DEVICE)\n",
    "\n",
    "unk_id = tokenizer.encode(\"<unk>\", add_special_tokens=False)[0]\n",
    "tokenizer.pad_token_id = 2\n",
    "tokenizer.eos_token_id = 0\n",
    "\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "N_EMBEDDINGS = model.model.embed_tokens.weight.shape[0]\n",
    "print(\"Number of embeddings in tokenizer:\", N_EMBEDDINGS)\n",
    "\n",
    "projection = torch.load(\"/home/jovyan/shares/SR004.nfs2/chekalina/check_halu/ckpts/projection\", map_location=DEVICE)\n",
    "start_emb = torch.load(\"/home/jovyan/shares/SR004.nfs2/chekalina/check_halu/ckpts/SOI.pt\", map_location=DEVICE)\n",
    "end_emb = torch.load(\"/home/jovyan/shares/SR004.nfs2/chekalina/check_halu/ckpts/EOI.pt\", map_location=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcfbbe95-e58c-4454-9646-43c7cbd52fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd_df = pd.read_csv('/home/jovyan/shares/SR004.nfs2/chekalina/check_halu/83000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3c0a5d7-b003-45a5-a536-73ae2f09e46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "tds = Dataset.from_pandas(pd_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c378e1c-ab5a-490e-9f05-0fbf90ea4e1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer', 'ents', 'embs'],\n",
       "    num_rows: 72998\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c97a74b-2caf-4f6f-9b89-de162dfe5f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "lst = literal_eval(tds[10]['embs'])\n",
    "lst = [elem for elem in lst if elem != -111]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ac3706c-c3b3-42bb-a61d-7f74b9bcf1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from ast import literal_eval\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class PretrainDataset(Dataset):\n",
    "    def __init__(self, ds):\n",
    "        self.ds = ds\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        ents = self.ds[idx]['ents']\n",
    "        try:\n",
    "            lst = literal_eval(self.ds[idx]['embs'])\n",
    "            lst = [elem for elem in lst if elem != -111]\n",
    "            embs = np.array(lst)\n",
    "            #embs = np.reshape(embs, (-1, 200)) \n",
    "        except:\n",
    "            print (self.ds[idx]['embs'])\n",
    "        \n",
    "        return self.ds[idx]['question'], self.ds[idx]['answer'], ents, embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62ba91ac-9ff5-4e45-a2a9-042c5a8dde08",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PretrainDataset(tds)\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e06bac0-8ec3-443f-944f-cf7b2ca84768",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c, d = dataset[1777]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd71601b-54b7-48c1-873d-7497ebbafbcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 200)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a021d918-3f2d-4e27-82ea-93db66662ec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 200)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array(d).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffaad73a-8d76-43ab-9b13-b5dd647e5243",
   "metadata": {},
   "source": [
    "### Train adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbe11e5b-d8d0-44b4-bfbd-70594592ecc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_words_ids = tokenizer([\"\\n\", \"</s>\", \":\"], add_special_tokens=False).input_ids + [[13]]\n",
    "gen_params = {\n",
    "        \"do_sample\": False,\n",
    "        \"max_new_tokens\": 20,\n",
    "        \"early_stopping\": False,\n",
    "        \"num_beams\": 3,\n",
    "        \"repetition_penalty\": 2.0,\n",
    "        \"remove_invalid_values\": True,\n",
    "        \"eos_token_id\": 0,\n",
    "        \"pad_token_id\": 2,\n",
    "        \"forced_eos_token_id\": 0,\n",
    "        \"use_cache\": True,\n",
    "        \"no_repeat_ngram_size\": 2,\n",
    "        \"bad_words_ids\": bad_words_ids,\n",
    "        \"num_return_sequences\": 3,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c3bdf57-ac02-4d09-b16d-54f2b008e4f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "285"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataloader) // 256 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b551fbeb-6ebb-4081-81bf-7a523c44398d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd7f8c146afc441c92800d1ed501fd42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/72998 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Songs from the Southern Mountains is the title of a recording by a folk music artist that has won how many Grammy awards?\n",
      "\n",
      " last part \n",
      "\n",
      "seven\n",
      "\n",
      " continue  's Grammy Award for Best Traditional Folk Album in 1962. The album was produced by Ralph Rinzler<unk>\n",
      "\n",
      "\n",
      "loss 8.006061553955078\n",
      "lr 0.0 0\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "512\n",
      "Lynda Bird Johnson Robb has an elder brother who died in 2013, and he was ambassador to which European country?\n",
      "\n",
      " last part \n",
      "\n",
      "Belgium\n",
      "\n",
      " continue  1960s, Lynda Bird Johnson Robb's father was the 36th President of the United States. Who was he? a.<unk>\n",
      "\n",
      "\n",
      "loss 3.7830482571143804\n",
      "lr 0.0005 512\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "1024\n",
      "Where is the group, which organised the Mexican referendums, 1989, based?\n",
      "\n",
      " last part \n",
      "\n",
      "Chiapas\n",
      "\n",
      " continue  2. What is the name of the group, which organised the Mexican referendums, 198<unk>\n",
      "\n",
      "\n",
      "loss 3.2976104953137053\n",
      "lr 0.0015 1024\n",
      "1536\n",
      "The actress that won The Gilded Balloon's So You Think You're Funny award at the Edinburgh Festival Fringe in 2012 is currently a captain on what tv game show?\n",
      "\n",
      " last part \n",
      "\n",
      "8 Out of 10 Cats\n",
      "\n",
      " continue  1. Pointless 2. Celebrity Juice 3. Never Mind the Buzzcocks 4. Mock the Week Answer at the end of the quiz! Question 5/10 Pick your poison<unk>\n",
      "\n",
      "\n",
      "loss 2.92948178608579\n",
      "lr 0.0025 1536\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "2048\n",
      "Who in the Scottish band formed in 1982 played guitar?\n",
      "\n",
      " last part \n",
      "\n",
      "Graeme Duffin\n",
      "\n",
      " continue  Scottish band formed in 1982 played guitar? Answer: Simple Minds.<unk>\n",
      "\n",
      "\n",
      "loss 2.5093378970014903\n",
      "lr 0.0034999999999999996 2048\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "2560\n",
      "Who is best known for his \"Mad Max\" franchise, with \"The Road Warrior\", that has  an arena for steel-cage jousting in the Australian post-apocalyptic film?\n",
      "\n",
      " last part \n",
      "\n",
      "George Miller\n",
      "\n",
      " continue  1981 film \"Mad Max 2: The Road Warrior\" is directed by George Miller and stars Mel Gibson as the title character. The film is set in a post-apocalyptic Australia<unk>\n",
      "\n",
      "\n",
      "loss 2.185735536481791\n",
      "lr 0.0045000000000000005 2560\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "3072\n",
      "Michael Kelso is one of the male leads on the show that was set in what fictional Wisconsin town?\n",
      "\n",
      " last part \n",
      "\n",
      "Point Place\n",
      "\n",
      " continue  Point Place, Wisconsin (That '70s Show) Michael Kelso is one of the male leads on the show that<unk>\n",
      "\n",
      "\n",
      "loss 1.9964403510863378\n",
      "lr 0.0049998368678171295 3072\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "3584\n",
      "Of the directors Neil Jordan and Shane Black, which one appeared acting in \"Predator\" in 1987?\n",
      "\n",
      " last part \n",
      "\n",
      "Shane Black\n",
      "\n",
      " continue  Neil Jordan. Shane Black appeared in \"Lethal Weapon\" (1987) and \"The Long Kiss Goodnight\"(<unk>\n",
      "\n",
      "\n",
      "loss 1.9856086031068116\n",
      "lr 0.004998531938089503 3584\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "4096\n",
      "When was the final tunnel joint installed on the only way across the Lingdingyang other than the Humen Pearl River Bridge?\n",
      "\n",
      " last part \n",
      "\n",
      "2nd of May, 2017\n",
      "\n",
      " continue  1998. The tunnel was opened to traffic on 30 December 2004. It is the only way across the<unk>\n",
      "\n",
      "\n",
      "loss 1.5131467891455046\n",
      "lr 0.004995922759815339 4096\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "4608\n",
      "Who has won more Tony Award's, Alex Greenwald or Constantine Maroulis?\n",
      "\n",
      " last part \n",
      "\n",
      "Constantine James Maroulis\n",
      "\n",
      " continue  Alex Greenwald has won more Tony Award's than Constantine Maroulis, winning one award for his performance in<unk>\n",
      "\n",
      "\n",
      "loss 1.725586116432392\n",
      "lr 0.004992010695001229 4608\n",
      "5120\n",
      "Gerard Johnson was the creator of a fountain for the country house that is of what type of architecture?\n",
      "\n",
      " last part \n",
      "\n",
      "Jacobean\n",
      "\n",
      " continue  Romanesque Revival style architecture (1850s) and Gothic Revivial style (late 1<unk>\n",
      "\n",
      "\n",
      "loss 1.600247749501202\n",
      "lr 0.004986797785768296 5120\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "5632\n",
      "The comedian behind Stripped appears as which character in \"The Riches\"?\n",
      "\n",
      " last part \n",
      "\n",
      "Wayne Malloy\n",
      "\n",
      " continue  Dahlia Malloy (played by Minnie Driver) is a con artist who poses<unk>\n",
      "\n",
      "\n",
      "loss 1.6026730118029648\n",
      "lr 0.004980286753286195 5632\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "6144\n",
      "University of California, San Diego and Tribhuvan University, are universities of which mutual type?\n",
      "\n",
      " last part \n",
      "\n",
      "public\n",
      "\n",
      " continue  research university and comprehensive university, respectively. The University of California, San Diego is a member of the Association of American<unk>\n",
      "\n",
      "\n",
      "loss 1.5492472079517488\n",
      "lr 0.004972480996352643 6144\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "6656\n",
      "Mark Stuart and Vincent Walker both are known as what in their bands?\n",
      "\n",
      " last part \n",
      "\n",
      "singer\n",
      "\n",
      " continue  guitarists and vocalists, respectively. Mark Stuart is also known as a songwriter<unk>\n",
      "\n",
      "\n",
      "loss 1.5081594324759229\n",
      "lr 0.004963384589619232 6656\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "7168\n",
      "Which Bulgarian operatic soprano had her career launched at Operalia, the World Opera Competition?\n",
      "\n",
      " last part \n",
      "\n",
      "Sonya Yoncheva\n",
      "\n",
      " continue  Bulgarian soprano Sonya Yoncheva (Bulgarian: Соня Йончева; born<unk>\n",
      "\n",
      "\n",
      "loss 1.435158981369176\n",
      "lr 0.004953002281464432 7168\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "7680\n",
      "Where was the band that made the song \"Disarm\" formed?\n",
      "\n",
      " last part \n",
      "\n",
      "Chicago, Illinois\n",
      "\n",
      " continue  Chicago, Illinois, United States of America (USA) in 1987.<unk>\n",
      "\n",
      "\n",
      "loss 1.4975493377169018\n",
      "lr 0.004941339491514909 7680\n",
      "8192\n",
      "In what year was the author of the Japanese manga \"Gyo\" born? \n",
      "\n",
      " last part \n",
      "\n",
      "1963\n",
      "\n",
      " continue  1967 (July 20) in Tokyo, Japan. Junji Ito<unk>\n",
      "\n",
      "\n",
      "loss 1.5105313603864974\n",
      "lr 0.004928402307816451 8192\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "8704\n",
      "Noshaq and Apsarasas Kangri, are mountains?\n",
      "\n",
      " last part \n",
      "\n",
      "no\n",
      "\n",
      " continue  yes, they are mountains. Noshaq is 7,492 metres (2<unk>\n",
      "\n",
      "\n",
      "loss 1.5594724580768566\n",
      "lr 0.00491419748365597 8704\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "9216\n",
      "When was the production company that created a fourth animated adaptation of the X-Men characters incorporated?\n",
      "\n",
      " last part \n",
      "\n",
      "January 25, 2008\n",
      "\n",
      " continue  November 1997, as Marvel Enterprises, Inc. (now Marvel Entertainment LLC) in New York<unk>\n",
      "\n",
      "\n",
      "loss 1.4205635824339249\n",
      "lr 0.004898732434036244 9216\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "9728\n",
      "What is the ethnicity of the football player who played for both Watford Football Club and Tottenham Hotspur?\n",
      "\n",
      " last part \n",
      "\n",
      "Danish\n",
      "\n",
      " continue  English and Nigerian footballer Emmanuel Emenike, who plays as a striker for Turkish Süper Lig club Beşikta<unk>\n",
      "\n",
      "\n",
      "loss 1.4512627464105807\n",
      "lr 0.004882015231805244 9728\n",
      "10240\n",
      "Able to be seen as modern-day vanitas paintings are Hyman Bloom's still life paintings featuring 19th-century containers of a characteristic shape and size descending from at least as early as what period?\n",
      "\n",
      " last part \n",
      "\n",
      "Neolithic Period\n",
      "\n",
      " continue  Renaissance period, 1400–1650 CE. The term \"vanitas\" is derived from the Latin word vanitas, meaning \"emptiness\" or \"futility\", and refers to the transience of life<unk>\n",
      "\n",
      "\n",
      "loss 1.5325483783261804\n",
      "lr 0.004864054603442062 10240\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "10752\n",
      "Which film exposes the former President of the Fundamentalist Church of Jesus?\n",
      "\n",
      " last part \n",
      "\n",
      "Banking on Heaven\n",
      "\n",
      " continue  The Eyes of Tammy Faye (2021) film directed by Michael Showalter<unk>\n",
      "\n",
      "\n",
      "loss 1.2811191537283102\n",
      "lr 0.00484485992450163 10752\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "11264\n",
      "What was the nationality of the star of \"Bob\"?\n",
      "\n",
      " last part \n",
      "\n",
      "American\n",
      "\n",
      " continue  American, born in Brooklyn, New York City, U.S.A.<unk>\n",
      "\n",
      "\n",
      "loss 1.5119553859299049\n",
      "lr 0.004824441214720628 11264\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "11776\n",
      "Mill district neighborhood is bounded to the east by a bridge with how many lanes ?\n",
      "\n",
      " last part \n",
      "\n",
      "eight-lane\n",
      "\n",
      " continue  four lanes (two in each direction) and a sidewalk on each side of the roadway.<unk>\n",
      "\n",
      "\n",
      "loss 1.597551209913247\n",
      "lr 0.004802809132787126 11776\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "12288\n",
      "What 23-storey residential skyscraper opened to the public on March 22, 2012?\n",
      "\n",
      " last part \n",
      "\n",
      "The Regent\n",
      "\n",
      " continue  8 Spruce Street, also known as New York by Gehry and Beekman Tower, is a residential skyscraper located at<unk>\n",
      "\n",
      "\n",
      "loss 1.654987690043755\n",
      "lr 0.0047799749707766745 12288\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "12800\n",
      "What American political activist and commentator was almost beheaded by Boston-area resident Usaama Rahim?\n",
      "\n",
      " last part \n",
      "\n",
      "Pamela Geller\n",
      "\n",
      " continue  Bill O'Reilly. Rahim was shot and killed by Boston Police Department officers on June 3, 201<unk>\n",
      "\n",
      "\n",
      "loss 1.6384000295158667\n",
      "lr 0.004755950648257789 12800\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "13312\n",
      "Who has more species, Macleaya or Mammillaria?\n",
      "\n",
      " last part \n",
      "\n",
      "Mammillaria\n",
      "\n",
      " continue  Mammillaria. Macleaya has about 20 species, while M<unk>\n",
      "\n",
      "\n",
      "loss 1.83335570800564\n",
      "lr 0.004730748706069848 13312\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "13824\n",
      "When did Şehzade Mehmed Abid's father begin his rule of the Ottoman Empire?\n",
      "\n",
      " last part \n",
      "\n",
      "31 August 1876\n",
      "\n",
      " continue  1566 CE, when he became Sultan of the Ottoman Empire upon the death of his father, Suleiman<unk>\n",
      "\n",
      "\n",
      "loss 1.651713728148346\n",
      "lr 0.004704382299776715 13824\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "14336\n",
      "Which came first for Buzz Aldrin, the walk on the moon, or being portrayed in a movie?\n",
      "\n",
      " last part \n",
      "\n",
      "July 21, 1969\n",
      "\n",
      " continue  the walk on the moon. Buzz Aldrin was portrayed by Lance Henriksen in the 1989<unk>\n",
      "\n",
      "\n",
      "loss 1.4378324202027735\n",
      "lr 0.004676865192799444 14336\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import AdamW\n",
    "from transformers.optimization import (Adafactor, AdafactorSchedule,\n",
    "                                       get_cosine_schedule_with_warmup)\n",
    "\n",
    "import gc\n",
    "\n",
    "import tqdm\n",
    "\n",
    "kg_emb_dim = 200\n",
    "mstral_emb_dim = 4096\n",
    "\n",
    "#start_emb = torch.normal(torch.zeros(mstral_emb_dim), torch.ones(mstral_emb_dim) / mstral_emb_dim**0.5).to(device=DEVICE, dtype=model.dtype)\n",
    "#end_emb = torch.normal(torch.zeros(mstral_emb_dim), torch.ones(mstral_emb_dim) / mstral_emb_dim**0.5).to(device=DEVICE, dtype=model.dtype)\n",
    "#projection = nn.Linear(kg_emb_dim, mstral_emb_dim).to(device=DEVICE, dtype=model.dtype)\n",
    "\n",
    "start_emb.requires_grad_()\n",
    "end_emb.requires_grad_()\n",
    "projection.requires_grad_()\n",
    "model.requires_grad_(False)\n",
    "\n",
    "    \n",
    "lr = 5e-3\n",
    "weight_decay = 1e-5\n",
    "trainable_parameters = [start_emb] + [end_emb] + list(projection.parameters())\n",
    "\n",
    "opt = AdamW(trainable_parameters, lr=lr, weight_decay=weight_decay)\n",
    "loss_fct = nn.CrossEntropyLoss(reduction=\"none\", ignore_index=unk_id)\n",
    "\n",
    "grad_accum = 256\n",
    "\n",
    "loss_best = 1000.0\n",
    "\n",
    "losses = []\n",
    "losses_batch = []\n",
    "iters = 0\n",
    "n_iters = len(dataloader)\n",
    "scheduler = get_cosine_schedule_with_warmup(opt, num_warmup_steps=10, num_training_steps=n_iters // grad_accum)\n",
    "\n",
    "for epoch in range(1):\n",
    "    i = 0 \n",
    "    for step in tqdm.notebook.tqdm(range(n_iters)):\n",
    "        batch = next(iter(dataloader))\n",
    "        question, answer, ents, embs = batch\n",
    "        model.eval()\n",
    "        model.requires_grad = False\n",
    "        #opt.zero_grad()\n",
    "        with torch.no_grad():\n",
    "            #print (question, answer)\n",
    "            text_ids_in = tokenizer.encode(question[0], add_special_tokens=False, return_tensors=\"pt\").to(device=DEVICE)\n",
    "            text_ids_out = tokenizer.encode(answer[0], add_special_tokens=False, return_tensors=\"pt\").to(device=DEVICE)\n",
    "            input_embeddings = model.model.embed_tokens(text_ids_in)\n",
    "            output_embeddings = model.model.embed_tokens(text_ids_out)\n",
    "            \n",
    "            #output_embeddings = model.model.embed_tokens(text_ids[...,:text_ids.shape[1]//2])\n",
    "            #output_embeddings = model.model.embed_tokens(text_ids[...,text_ids.shape[1]//2+1:])\n",
    "            \n",
    "        try:\n",
    "            m = embs.mean(2, keepdim=True)\n",
    "            s = embs.std(2, unbiased=False, keepdim=True)\n",
    "            embs -= m\n",
    "            embs /= s\n",
    "        except Exception as e:\n",
    "            print (e)\n",
    "            continue\n",
    "        try:\n",
    "            projected_kg_embeddings = projection(embs.to(\n",
    "                        device=DEVICE, dtype=model.dtype\n",
    "                    ))\n",
    "        except Exception as e:\n",
    "            print (e)\n",
    "            print (\"embs.shape\", embs.shape)\n",
    "            continue\n",
    "        \n",
    "        embeddings1 = torch.cat(\n",
    "                [\n",
    "                    input_embeddings,\n",
    "                    start_emb[None, None, ...],\n",
    "                    projected_kg_embeddings,\n",
    "                    end_emb[None, None, ...]\n",
    "                ],\n",
    "                dim=1,\n",
    "            )\n",
    "        \n",
    "        gen_params['max_new_tokens'] = embeddings1.shape[1]\n",
    "        \n",
    "        #mask = torch.full(embeddings1.shape, False)\n",
    "        \n",
    "        with torch.autocast(device_type=\"cuda\", dtype=model.dtype):\n",
    "            logits = model(inputs_embeds=torch.cat(\n",
    "                [\n",
    "                    input_embeddings,\n",
    "                    start_emb[None, None, ...],\n",
    "                    projected_kg_embeddings,\n",
    "                    end_emb[None, None, ...],\n",
    "                    output_embeddings\n",
    "                ],\n",
    "                dim=1,\n",
    "            ), output_hidden_states=True).get(\"logits\")\n",
    "            # loss only for answer part & backward\n",
    "            #print (answer)\n",
    "            #print (output_embeddings.shape)\n",
    "            #logits = logits[..., -output_embeddings.shape[1]:, :].contiguous()\n",
    "            #labels = text_ids_out.contiguous()\n",
    "            logits = logits[..., embeddings1.shape[1] - 1 : -1, :].contiguous()\n",
    "            labels = text_ids_out.contiguous()\n",
    "            loss = loss_fct(logits.permute(0, 2, 1), labels).mean()\n",
    "            #print (\"logits.shape\", logits.shape)\n",
    "            #print (\"labels.shape\", labels.shape)\n",
    "            #shift_logits = logits[..., :-1, :].contiguous()\n",
    "            #shift_labels = labels[..., 1:].contiguous()\n",
    "            #print (\"logits.shape\", shift_logits.shape)\n",
    "            #print (\"shift_labels\", shift_labels.shape)\n",
    "            #print (\"output_embeddings\", output_embeddings.shape)\n",
    "            \n",
    "            #labels = labels[...,:text_ids.shape[1]//2]\n",
    "            \n",
    "            #mask = mask[:, -output_embeddings.shape[1]:]\n",
    "        \n",
    "            #print (\"logits.shape\", logits.shape)\n",
    "            #print (\"labels.shape\", labels.shape)\n",
    "            #loss = loss_fct(shift_logits.permute(0, 2, 1), shift_labels).mean()\n",
    "            #print (loss)\n",
    "            \n",
    "        if model.dtype == torch.float16:\n",
    "            scaler.scale(loss).backward()\n",
    "        else:\n",
    "            loss.backward()\n",
    "        losses_batch.append(loss.item())\n",
    "        \n",
    "        if (step % (2*grad_accum) == 0):  \n",
    "            print (step)\n",
    "            out = model.generate(inputs_embeds=embeddings1, **gen_params)\n",
    "            #print (\"out.shape\", out.shape)\n",
    "            #print (\"projected_kg_embeddings shape\", projected_kg_embeddings.shape)\n",
    "            #out = out[:, 1:]\n",
    "            #print (\"out.shape\", out.shape)\n",
    "            generated_texts = tokenizer.batch_decode(out)[0]\n",
    "            print (question[0])\n",
    "            print (\"\\n last part \\n\")\n",
    "            print (answer[0])\n",
    "            print (\"\\n continue\", generated_texts)\n",
    "            print (\"\\n\")\n",
    "            \n",
    "            print (\"loss\", np.mean(losses_batch))\n",
    "            print ('lr', scheduler.get_lr()[0], step, flush = True)\n",
    "            plt.title(\"train loss\\n\" + f\"\\n\\nEpoch [{epoch}], iter [{iters}/{n_iters}]\")\n",
    "            accum_loss = np.mean(losses_batch)\n",
    "            losses.append(accum_loss)\n",
    "            plt.semilogy(losses)\n",
    "            plt.grid()\n",
    "            plt.savefig(f\"ckpts/loss3.png\")\n",
    "            plt.close(\"all\")\n",
    "\n",
    "\n",
    "        if iters % grad_accum == 0 and iters > 0:\n",
    "            if model.dtype == torch.float16:\n",
    "                scaler.step(opt)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                opt.step()\n",
    "            opt.zero_grad()\n",
    "            scheduler.step()\n",
    "            accum_loss = np.mean(losses_batch)\n",
    "            losses.append(accum_loss)\n",
    "            losses_batch = []\n",
    "\n",
    "            if accum_loss < loss_best:\n",
    "                loss_best = accum_loss\n",
    "                torch.save(projection, f\"ckpts/projection_qa1\")\n",
    "                torch.save(start_emb, f\"ckpts/SOI2_qa1.pt\")\n",
    "                torch.save(end_emb, f\"ckpts/EOI2_qa1.pt\")\n",
    "            \n",
    "            \n",
    "            #gc.collect()\n",
    "        \n",
    "        iters += 1\n",
    "\n",
    "        # model inference to get\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a9505b-f154-45f9-a3c3-3d23ae6eab63",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.generate(inputs_embeds=embeddings1, **gen_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011c5d7d-0bc6-4f32-b92b-94d742b34925",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings1 = torch.cat(\n",
    "                [\n",
    "                    input_embeddings,\n",
    "                    start_emb[None, None, ...],\n",
    "                    projected_kg_embeddings,\n",
    "                    end_emb[None, None, ...],\n",
    "                    output_embeddings\n",
    "                ],\n",
    "                dim=1,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2d33f8-0baf-417e-bfba-bd7d36a7ff8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model.generate(inputs_embeds=embeddings1,\n",
    "    do_sample=True,\n",
    "    max_new_tokens=150,\n",
    "    top_p=0.82,\n",
    "    top_k=0,\n",
    "    eos_token_id= 0,\n",
    "    pad_token_id=2,\n",
    "    temperature=3.5)\n",
    "\n",
    "print (\"out.shape\", out.shape)\n",
    "out = out[:, 1:]\n",
    "\n",
    "generated_texts = tokenizer.batch_decode(out)[0]\n",
    "\n",
    "generated_texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139f3ed3-2cdb-4bc1-9733-f0afd777a5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_params = {\n",
    "        \"do_sample\": False,\n",
    "        \"max_new_tokens\": 150,\n",
    "        \"early_stopping\": False,\n",
    "        \"num_beams\": 3,\n",
    "        \"repetition_penalty\": 2.0,\n",
    "        \"remove_invalid_values\": True,\n",
    "        \"eos_token_id\": 0,\n",
    "        \"pad_token_id\": 2,\n",
    "        \"forced_eos_token_id\": 0,\n",
    "        \"use_cache\": True,\n",
    "        \"no_repeat_ngram_size\": 2,\n",
    "        \"bad_words_ids\": bad_words_ids,\n",
    "        \"num_return_sequences\": 3,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de77c14-202b-4e5f-bbaf-79ae9aac4614",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model.generate(inputs_embeds=embeddings1,\n",
    "    **gen_params)\n",
    "\n",
    "print (\"out.shape\", out.shape)\n",
    "#out = out[:, 1:]\n",
    "\n",
    "generated_texts = tokenizer.decode(out)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db322041-00ef-47f4-ae0c-0652053d6de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f892941-5050-49c9-b0bc-2f158d170fc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.mlspace-Python310]",
   "language": "python",
   "name": "conda-env-.mlspace-Python310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

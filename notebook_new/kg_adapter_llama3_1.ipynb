{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51f5a1e2-3069-4e4f-b972-ca67e249d6bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-17 14:58:08,618] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "Warning: The cache directory for DeepSpeed Triton autotune, /home/jovyan/.triton/autotune, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.mlspace/envs/vika_kurkin_clone/bin/../lib/gcc/x86_64-conda-linux-gnu/12.4.0/../../../../x86_64-conda-linux-gnu/bin/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "/home/jovyan/.mlspace/envs/vika_kurkin_clone/bin/../lib/gcc/x86_64-conda-linux-gnu/12.4.0/../../../../x86_64-conda-linux-gnu/bin/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New EOS token ID: 128001\n",
      "Special tokens: {'bos_token': '<|begin_of_text|>', 'eos_token': '<|end_of_text|>', 'pad_token': '<|finetune_right_pad_id|>', 'unk_token': None, 'additional_special_tokens': []}\n",
      "Token IDs: {'bos_token': 128000, 'eos_token': 128001, 'pad_token': 128004, 'additional_special_tokens': []}\n",
      "Number of embeddings in tokenizer: 128256\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from urllib.request import urlopen\n",
    "import torch.nn as nn\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Loading some sources of the projection adapter and image encoder\n",
    "#hf_hub_download(repo_id=\"AIRI-Institute/OmniFusion\", filename=\"models.py\", local_dir='./')\n",
    "#from models import CLIPVisionTower\n",
    "\n",
    "DEVICE = \"cuda:3\"\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "\n",
    "model_id = \"unsloth/llama-3.2-1b\"  # or \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map={\"\": DEVICE}\n",
    ")\n",
    "model.eval()\n",
    "#new_eos_token = \"<|eos|>\"\n",
    "\n",
    "# Set it and add to tokenizer\n",
    "#tokenizer.eos_token = new_eos_token\n",
    "#tokenizer.add_special_tokens({'eos_token': new_eos_token})\n",
    "\n",
    "# Check ID\n",
    "print(\"New EOS token ID:\", tokenizer.eos_token_id)\n",
    "\n",
    "special_tokens = {\n",
    "    \"bos_token\": tokenizer.bos_token,\n",
    "    \"eos_token\": tokenizer.eos_token,\n",
    "    \"pad_token\": tokenizer.pad_token,\n",
    "    \"unk_token\": tokenizer.unk_token,\n",
    "    \"additional_special_tokens\": tokenizer.additional_special_tokens,\n",
    "}\n",
    "\n",
    "special_token_ids = {\n",
    "    name: tokenizer.convert_tokens_to_ids(token)\n",
    "    for name, token in special_tokens.items()\n",
    "    if isinstance(token, str) or token is not None\n",
    "}\n",
    "\n",
    "print(\"Special tokens:\", special_tokens)\n",
    "print(\"Token IDs:\", special_token_ids)\n",
    "\n",
    "unk_id = tokenizer.encode(\"<unk>\", add_special_tokens=False)[0]\n",
    "#tokenizer.pad_token_id = 2\n",
    "#tokenizer.eos_token_id = 0\n",
    "\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "N_EMBEDDINGS = model.model.embed_tokens.weight.shape[0]\n",
    "print(\"Number of embeddings in tokenizer:\", N_EMBEDDINGS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48bcf5e5-67a1-4922-a080-52c4a55cbe1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unk_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acb6e1e7-500b-4928-8e9e-a638b30f2019",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0052389c08b4d26adc1960ef45111b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/58 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dffd378d756410fbc688682144cc1f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/58 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a25563ecbccc4e68b474128928a254e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"Sayankotor/small_wikipaper\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fd09452-55e0-4d8e-b71f-a8dd7731f533",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "\n",
    "class PretrainDataset(Dataset):\n",
    "    def __init__(self, ds):\n",
    "        # Ensure 'entities' is parsed if stored as string\n",
    "        self.ds = [\n",
    "            item for item in ds['train']\n",
    "            if len(literal_eval(item['entities'])) > 1\n",
    "        ]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.ds[idx]\n",
    "        try:\n",
    "            text = item['text'][:2048]\n",
    "        except Exception:\n",
    "            print(\"Bad example (no text):\", item)\n",
    "            text = \"Bad example\"\n",
    "        \n",
    "        ents = literal_eval(item['entities'])\n",
    "        embs = np.array(literal_eval(item['entity_embs']))[:200]\n",
    "\n",
    "        return text, ents, embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0177812-f46e-4aae-a365-76beb96288e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "g = torch.Generator()\n",
    "g.manual_seed(42)\n",
    "\n",
    "subset_indices = list(range(16000))\n",
    "random.shuffle(subset_indices)\n",
    "dataset = PretrainDataset(ds)\n",
    "# Wrap the dataset with Subset\n",
    "subset = Subset(dataset, subset_indices)\n",
    "\n",
    "# Create the dataloader\n",
    "dataloader = DataLoader(subset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f28f646-8a47-4a97-a484-6fc8eca53a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import AdamW\n",
    "from transformers.optimization import (Adafactor, AdafactorSchedule,\n",
    "                                       get_cosine_schedule_with_warmup)\n",
    "\n",
    "import gc\n",
    "\n",
    "import tqdm\n",
    "\n",
    "kg_emb_dim = 200\n",
    "llama_emb_dim = 2048\n",
    "\n",
    "\n",
    "kg_start_emb = torch.normal(\n",
    "    torch.zeros(llama_emb_dim), \n",
    "    torch.ones(llama_emb_dim) / llama_emb_dim**0.5\n",
    ").to(device=DEVICE, dtype=torch.bfloat16)\n",
    "\n",
    "kg_end_emb = torch.normal(\n",
    "    torch.zeros(llama_emb_dim), \n",
    "    torch.ones(llama_emb_dim) / llama_emb_dim**0.5\n",
    ").to(device=DEVICE, dtype=torch.bfloat16)\n",
    "\n",
    "projection = nn.Linear(kg_emb_dim, llama_emb_dim).to(device=DEVICE, dtype=torch.bfloat16)\n",
    "\n",
    "kg_start_emb.requires_grad_()\n",
    "kg_end_emb.requires_grad_()\n",
    "model.requires_grad_(False)\n",
    "projection.requires_grad_()\n",
    "    \n",
    "lr = 5e-3\n",
    "weight_decay = 1e-3\n",
    "trainable_parameters = [kg_start_emb] + [kg_end_emb] + list(projection.parameters())\n",
    "\n",
    "opt = AdamW(trainable_parameters, lr=lr, weight_decay=weight_decay)\n",
    "loss_fct = nn.CrossEntropyLoss(reduction=\"none\", ignore_index=unk_id)\n",
    "\n",
    "grad_accum = 256\n",
    "\n",
    "loss_best = 1000.0\n",
    "\n",
    "losses = []\n",
    "losses_batch = []\n",
    "iters = 0\n",
    "n_iters = len(dataloader)\n",
    "scheduler = get_cosine_schedule_with_warmup(opt, num_warmup_steps=n_iters // grad_accum * 0.01, num_training_steps=n_iters // grad_accum)\n",
    "\n",
    "for epoch in range(1):\n",
    "    i = 0 \n",
    "    for step in tqdm.notebook.tqdm(range(n_iters)):\n",
    "        batch = next(iter(dataloader))\n",
    "        text, ents, embs = batch\n",
    "        \n",
    "        model.eval()\n",
    "        model.requires_grad = False\n",
    "        opt.zero_grad()\n",
    "    \n",
    "        prompt = f\"Continue this text:\\n\\n{text[0]}\"\n",
    "\n",
    "\n",
    "        with torch.no_grad():\n",
    "            text_ids = tokenizer.encode(prompt, add_special_tokens=False, return_tensors=\"pt\")[..., :2048].to(device=DEVICE)\n",
    "\n",
    "            text_ids = tokenizer.encode(prompt, add_special_tokens=False)[:2048]\n",
    "            \n",
    "            # Step 2: Add special tokens manually\n",
    "            text_ids += [tokenizer.eos_token_id]\n",
    "            \n",
    "            # Step 3: Convert to tensor\n",
    "            text_ids = torch.tensor([text_ids], device=DEVICE)\n",
    "            \n",
    "            half = text_ids.shape[1] // 2  # use shape[1] for token length\n",
    "            input_embeddings = model.model.embed_tokens(text_ids[:, :half])\n",
    "            output_embeddings = model.model.embed_tokens(text_ids[:, half:])\n",
    "            \n",
    "        try:\n",
    "            m = batch[2].mean(2, keepdim=True)\n",
    "            s = batch[2].std(2, unbiased=False, keepdim=True)\n",
    "            batch[2] = (batch[2] - m) / (s + 1e-6)\n",
    "        except:\n",
    "            print (\"except\", batch[2].shape)\n",
    "        try:\n",
    "            projected_kg_embeddings = projection(batch[2].to(\n",
    "                        device=DEVICE, dtype=model.dtype\n",
    "                    ))\n",
    "        except Exception as e:\n",
    "            print(\"❌ Error projecting KG embeddings\")\n",
    "            print(\"embs.shape:\", batch[2].shape)\n",
    "            print(\"Exception:\", str(e))\n",
    "            continue\n",
    "        \n",
    "        embeddings1 = torch.cat(\n",
    "                [\n",
    "                    kg_start_emb[None, None, ...],\n",
    "                    projected_kg_embeddings,\n",
    "                    kg_end_emb[None, None, ...],\n",
    "                    input_embeddings,\n",
    "                    output_embeddings\n",
    "                ],\n",
    "                dim=1,\n",
    "            )\n",
    "        \n",
    "        #mask = torch.full(embeddings1.shape, False)\n",
    "        \n",
    "        with torch.autocast(device_type=\"cuda\", dtype=model.dtype):\n",
    "            logits = model(inputs_embeds=torch.cat(\n",
    "                [\n",
    "                    kg_start_emb[None, None, ...],\n",
    "                    projected_kg_embeddings,\n",
    "                    kg_end_emb[None, None, ...],\n",
    "                    input_embeddings,\n",
    "                    output_embeddings\n",
    "                ],\n",
    "                dim=1,\n",
    "            ), output_hidden_states=True).get(\"logits\")\n",
    "            # loss only for answer part & backward\n",
    "\n",
    "            logits = logits[..., -output_embeddings.shape[1]:-1, :].contiguous()\n",
    "            labels = text_ids[:, half+1:].contiguous()\n",
    "\n",
    "            if torch.isnan(logits).any():\n",
    "                print(\"⚠️ NaN in logits\")\n",
    "            \n",
    "\n",
    "            loss = loss_fct(logits.permute(0, 2, 1), labels).mean()\n",
    "\n",
    "        if model.dtype == torch.float16:\n",
    "            scaler.scale(loss).backward()\n",
    "        else:\n",
    "            loss.backward()\n",
    "        losses_batch.append(loss.item())\n",
    "        \n",
    "        if (step% 1000 == 0):         \n",
    "            out = model.generate(inputs_embeds=embeddings1, max_new_tokens = half)\n",
    "            generated_texts2 = tokenizer.batch_decode(out)[0]\n",
    "            print (\"\\n first part \\n\")\n",
    "            print(tokenizer.decode(text_ids[0, :half].tolist(), skip_special_tokens=True))\n",
    "            print(\"\\n last part \\n\")\n",
    "            print(tokenizer.decode(text_ids[0, half:].tolist(), skip_special_tokens=True))\n",
    "            print (\"\\n continue\", generated_texts2)\n",
    "            print (\"\\n\")\n",
    "            \n",
    "            print (\"loss\", np.mean(losses_batch))\n",
    "            print ('lr', scheduler.get_lr()[0], step, flush = True)\n",
    "            plt.title(\"train loss\\n\" + f\"\\n\\nEpoch [{epoch}], iter [{iters}/{n_iters}]\")\n",
    "            accum_loss = np.mean(losses_batch)\n",
    "            losses.append(accum_loss)\n",
    "            plt.semilogy(losses)\n",
    "            plt.grid()\n",
    "            plt.savefig(f\"/home/jovyan/shares/SR004.nfs2/chekalina/kg_reduces_halus/notebook_new/ckpts/loss1_llama2.png\")\n",
    "            plt.close(\"all\")\n",
    "\n",
    "\n",
    "        if iters % grad_accum == 0 and iters > 0:\n",
    "            if model.dtype == torch.float16:\n",
    "                scaler.step(opt)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                opt.step()\n",
    "            opt.zero_grad()\n",
    "            scheduler.step()\n",
    "            accum_loss = np.mean(losses_batch)\n",
    "            losses.append(accum_loss)\n",
    "            losses_batch = []\n",
    "\n",
    "            if accum_loss < loss_best:\n",
    "                loss_best = accum_loss\n",
    "                torch.save(projection, f\"/home/jovyan/shares/SR004.nfs2/chekalina/kg_reduces_halus/notebook_new/ckpts/projection_llama3\")\n",
    "                torch.save(kg_start_emb, f\"/home/jovyan/shares/SR004.nfs2/chekalina/kg_reduces_halus/notebook_new/ckpts/SOI_llama3.pt\")\n",
    "                torch.save(kg_end_emb, f\"/home/jovyan/shares/SR004.nfs2/chekalina/kg_reduces_halus/notebook_new/ckpts/EOI_llama3.pt\")\n",
    "            \n",
    "            \n",
    "            #gc.collect()\n",
    "        \n",
    "        iters += 1\n",
    "\n",
    "        # model inference to get\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af458aa-20e7-4d8b-b88e-52a0561fd398",
   "metadata": {},
   "source": [
    "## QA sft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "139f3ed3-2cdb-4bc1-9733-f0afd777a5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd_df = pd.read_csv('/home/jovyan/shares/SR004.nfs2/chekalina/check_halu/83000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1de77c14-202b-4e5f-bbaf-79ae9aac4614",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "tds = Dataset.from_pandas(pd_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df96e3f3-c31b-4c1f-b577-3e968e3b6a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from word2number import w2n\n",
    "\n",
    "# Accept only alphabetic characters and hyphens/spaces\n",
    "pure_number_pattern = re.compile(r\"^[a-z\\s-]+$\", re.IGNORECASE)\n",
    "\n",
    "BLOCK_WORDS = {\n",
    "    \"half\", \"quarter\", \"percent\", \"times\", \"part\", \"copy\", \"copies\",\n",
    "    \"million\", \"billion\", \"trillion\",  # block these only in fuzzy use\n",
    "    \"more\", \"about\", \"around\", \"approximately\", \"nearly\", \"almost\", \"over\", \"under\",\n",
    "    \"in\", \"excess\", \"than\"\n",
    "}\n",
    "\n",
    "def normalize_answer_if_needed(example):\n",
    "    question = example[\"question\"].lower()\n",
    "    answer = example[\"answer\"].strip()\n",
    "    answer_lc = answer.lower()\n",
    "\n",
    "    if not (\"how many\" in question or \"how much\" in question):\n",
    "        return example\n",
    "\n",
    "    # Reject if any blocking word appears in answer\n",
    "    if any(block in answer_lc for block in BLOCK_WORDS):\n",
    "        return example\n",
    "\n",
    "    # Must match a clean number phrase (no digits, no punctuation)\n",
    "    if not pure_number_pattern.fullmatch(answer_lc):\n",
    "        return example\n",
    "\n",
    "    try:\n",
    "        number = w2n.word_to_num(answer_lc.replace(\"-\", \" \"))\n",
    "        example[\"answer\"] = str(number)\n",
    "    except ValueError:\n",
    "        pass  # not cleanly parseable\n",
    "\n",
    "    return example\n",
    "\n",
    "\n",
    "# do not do it!!!\n",
    "\n",
    "#tds = tds.map(normalize_answer_if_needed)\n",
    "\n",
    "#for i, (before, after) in enumerate(zip(original_answers, tds[\"answer\"])):\n",
    "#    if before != after:\n",
    "#        print(f\"[{i}] {before} → {after}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26f05892-5444-4536-b4f4-4b59af7b8d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from ast import literal_eval\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import AdamW\n",
    "from transformers.optimization import (Adafactor, AdafactorSchedule,\n",
    "                                       get_cosine_schedule_with_warmup)\n",
    "\n",
    "\n",
    "class PretrainDataset(Dataset):\n",
    "    def __init__(self, ds):\n",
    "        self.ds = [\n",
    "            item for item in ds if len(literal_eval(item['ents'])) > 1\n",
    "        ]\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        ents = literal_eval(self.ds[idx]['ents'])\n",
    "        try:\n",
    "            lst = literal_eval(self.ds[idx]['embs'])\n",
    "            lst = [elem for elem in lst if elem != -111]\n",
    "            embs = np.array(lst)\n",
    "            #embs = np.reshape(embs, (-1, 200)) \n",
    "        except:\n",
    "            print (self.ds[idx]['embs'])\n",
    "        \n",
    "        return self.ds[idx]['question'], self.ds[idx]['answer'], ents, embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ccc67d1b-bc59-47be-84fe-7bee29da790c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import random\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "g = torch.Generator()\n",
    "g.manual_seed(142)\n",
    "\n",
    "subset_indices = list(range(16000))\n",
    "random.shuffle(subset_indices)\n",
    "dataset = PretrainDataset(tds)\n",
    "# Wrap the dataset with Subset\n",
    "subset = Subset(dataset, subset_indices)\n",
    "\n",
    "# Create the dataloader\n",
    "dataloader = DataLoader(subset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6fc6a17-1a2e-4ae8-9b04-4ba4540615e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unk_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91c94910-6763-455f-9096-b69d2734c52e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bos_token_id = tokenizer.convert_tokens_to_ids(\"<|begin_of_text|>\")\n",
    "eos_token_id = tokenizer.convert_tokens_to_ids(\"<|end_of_text|>\")\n",
    "bos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ff26e25-a6ac-4ae7-ba17-85fbb6bb33fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128001"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8addd97-98cc-4e44-9009-875f19918c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jun 17 14:59:25 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA A100-SXM4-80GB          On  |   00000000:07:00.0 Off |                    0 |\n",
      "| N/A   35C    P0             83W /  400W |       4MiB /  81920MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  NVIDIA A100-SXM4-80GB          On  |   00000000:0A:00.0 Off |                    0 |\n",
      "| N/A   35C    P0            103W /  400W |    3389MiB /  81920MiB |     31%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   2  NVIDIA A100-SXM4-80GB          On  |   00000000:44:00.0 Off |                    0 |\n",
      "| N/A   35C    P0             85W /  400W |       4MiB /  81920MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   3  NVIDIA A100-SXM4-80GB          On  |   00000000:C2:00.0 Off |                    0 |\n",
      "| N/A   35C    P0             79W /  400W |    3285MiB /  81920MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    1   N/A  N/A     27918      C   python3                                      3380MiB |\n",
      "|    3   N/A  N/A     28173      C   ...e/envs/vika_kurkin_clone/bin/python       3276MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dec10afa-7f33-4601-8b7d-3ef005ed27ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f1faed802a74dc6aa61c563c9a7a9bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ents ['Great Reading Adventure', 'To Kill a Mockingbird']\n",
      "Token IDs: [1271, 27933, 264, 14905, 287, 23414, -100]\n",
      "Vocab size: 128000\n",
      "You are a knowledgeable assistant. Answer the question with a short, simple response. Avoid explanations.\n",
      "\n",
      "Great Reading Adventure was introduced in Bristol, inspired by a Chicago scheme that was using which 1960 Harper Lee novel as its springboard?\n",
      "\n",
      "Answer:\n",
      "\n",
      " last part \n",
      "\n",
      "To Kill a Mockingbird\n",
      "\n",
      " continue \n",
      "\n",
      "The Great Gatsby, by F. Scott Fitzgerald, was first published in 1925.\n",
      "\n",
      "The book was a success, selling 100,000 copies in the first year and 1 million copies in the first decade. It won the Pulitzer Prize in \n",
      "\n",
      "\n",
      "loss 2.673940420150757\n",
      "❌ Projection failed: Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "❌ Projection failed: Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "❌ Projection failed: Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "❌ Projection failed: Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "❌ Projection failed: Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "ents ['Dancing in the Dark (Rihanna song)', 'Home (soundtrack)']\n",
      "Token IDs: [10227, 3082, 49203, 315, 4487, 1247, 1316, -100]\n",
      "Vocab size: 128000\n",
      "You are a knowledgeable assistant. Answer the question with a short, simple response. Avoid explanations.\n",
      "\n",
      "Which book was the basis for the film which had Dancing in the Dark on its soundtrack?\n",
      "\n",
      "Answer:\n",
      "\n",
      " last part \n",
      "\n",
      "\"The True Meaning of Smekday\n",
      "\n",
      " continue \n",
      "\n",
      "A. The Tempest\n",
      "\n",
      "B. The Tempest\n",
      "\n",
      "C. The Tempest\n",
      "\n",
      "D. The Tempest\n",
      "\n",
      "Answer: A<|end_of_text|>\n",
      "\n",
      "\n",
      "loss 3.4950532852815637\n",
      "❌ Projection failed: Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "❌ Projection failed: Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "❌ Projection failed: Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "ents ['Alexander Korda', 'Spencer Gordon Bennet']\n",
      "Token IDs: [31255, 17276, 323, 7690, -100]\n",
      "Vocab size: 128000\n",
      "You are a knowledgeable assistant. Answer the question with a short, simple response. Avoid explanations.\n",
      "\n",
      "Alexander Korda and Spencer Gordon Bennet, have which mutual occupations?\n",
      "\n",
      "Answer:\n",
      "\n",
      " last part \n",
      "\n",
      "film producer and director\n",
      "\n",
      " continue Spencer Gordon Bennet is a director and producer, and Alexander Korda is a producer.\n",
      "\n",
      "Alexander Korda and Spencer Gordon Bennet, have which mutual occupations?\n",
      "\n",
      "Answer: Alexander Korda is\n",
      "\n",
      "\n",
      "loss 2.7216617508232592\n",
      "❌ Projection failed: Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "ents ['Anna Mikhalkova', 'Burnt by the Sun 2']\n",
      "Token IDs: [45, 1609, 6388, 386, 31603, 1727, 869, -100]\n",
      "Vocab size: 128000\n",
      "You are a knowledgeable assistant. Answer the question with a short, simple response. Avoid explanations.\n",
      "\n",
      "The actress that leads the tv program Spokoynoy nochi, malyshi! appears in a 2010 film directed by who?\n",
      "\n",
      "Answer:\n",
      "\n",
      " last part \n",
      "\n",
      "Nikita Mikhalkov\n",
      "\n",
      " continue Ava Gardner\n",
      "\n",
      "Explanation: Ava Gardner is an American actress. She was born in Philadelphia, Pennsylvania. She began her career in 1941. She appeared in many movies such as \"The Barefoot Contessa\", \"The Night of the Iguana\", and\n",
      "\n",
      "\n",
      "loss 2.568842742357935\n",
      "❌ Projection failed: Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "❌ Projection failed: Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "❌ Projection failed: Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "ents ['Alfred Santell', 'Anthony Kimmins']\n",
      "Token IDs: [2201, -100]\n",
      "Vocab size: 128000\n",
      "You are a knowledgeable assistant. Answer the question with a short, simple response. Avoid explanations.\n",
      "\n",
      "Were both Alfred Santell and Anthony Kimmins American?\n",
      "\n",
      "Answer:\n",
      "\n",
      " last part \n",
      "\n",
      "no\n",
      "\n",
      " continue both Alfred Santell and Anthony Kimmins were American\n",
      "\n",
      "How many years have you been a teacher?\n",
      "\n",
      "Answer: 10 years\n",
      "\n",
      "Where did you teach?\n",
      "\n",
      "Answer: I taught in\n",
      "\n",
      "\n",
      "loss 1.9621698830176044\n",
      "❌ Projection failed: Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "❌ Projection failed: Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "❌ Projection failed: Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "ents ['Tate Taylor', 'The Girl on the Train (2016 film)']\n",
      "Token IDs: [26368, 64, 70687, -100]\n",
      "Vocab size: 128000\n",
      "You are a knowledgeable assistant. Answer the question with a short, simple response. Avoid explanations.\n",
      "\n",
      "Tate Taylor directed the movie The Girl On The Train that was based on who's bestselling book?\n",
      "\n",
      "Answer:\n",
      "\n",
      " last part \n",
      "\n",
      "Paula Hawkins\n",
      "\n",
      " continue The Girl on the Train is a 2016 American psychological thriller film directed by Tate Taylor and starring Emily Blunt, Rebecca Ferguson, Justin Theroux, Allison Janney, and Justin Timberlake. It is based on the\n",
      "\n",
      "\n",
      "loss 2.1544568225864538\n",
      "❌ Projection failed: Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "❌ Projection failed: Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "❌ Projection failed: Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "ents ['Ruth Higham', 'Page 3']\n",
      "Token IDs: [10227, 8219, 1, -100]\n",
      "Vocab size: 128000\n",
      "You are a knowledgeable assistant. Answer the question with a short, simple response. Avoid explanations.\n",
      "\n",
      "Ruth Higham is a former \"Page 3\" girl,that modelled for which British tabloid newspaper?\n",
      "\n",
      "Answer:\n",
      "\n",
      " last part \n",
      "\n",
      "\"The Sun\"\n",
      "\n",
      " continue Daily Mirror\n",
      "\n",
      "### Question 4\n",
      "\n",
      "Which British tabloid newspaper is Ruth Higham a former model for?\n",
      "\n",
      "Answer: Daily Mirror\n",
      "\n",
      "### Question 5\n",
      "\n",
      "Which British tabloid newspaper is Ruth Higham a former model for?\n",
      "\n",
      "Answer: Daily\n",
      "\n",
      "\n",
      "loss 2.0886209294437728\n",
      "❌ Projection failed: Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "❌ Projection failed: Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "❌ Projection failed: Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "❌ Projection failed: Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "❌ Projection failed: Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "❌ Projection failed: Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "❌ Projection failed: Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "ents [\"Harry d'Abbadie d'Arrast\", 'Peter Faiman']\n",
      "Token IDs: [2201, -100]\n",
      "Vocab size: 128000\n",
      "You are a knowledgeable assistant. Answer the question with a short, simple response. Avoid explanations.\n",
      "\n",
      "Are Peter Faiman and Harry d'Abbadie d'Arrast from the same country?\n",
      "\n",
      "Answer:\n",
      "\n",
      " last part \n",
      "\n",
      "no\n",
      "\n",
      " continue noyes\n",
      "\n",
      "Explanation:\n",
      "\n",
      "Peter Faiman is a French actor and Harry d'Arrast is a French singer and actor.\n",
      "\n",
      "Source: https://en.wikipedia.org/wiki/Peter_Faiman\n",
      "\n",
      "Answer: Yes\n",
      "\n",
      "Explanation:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "loss 1.6936021493304343\n",
      "❌ Projection failed: Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "❌ Projection failed: Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "ents ['Bentley Continental Flying Spur (2005)', 'Volkswagen Phaeton']\n",
      "Token IDs: [50828, 330, 85694, 538, 1, 7458, -100]\n",
      "Vocab size: 128000\n",
      "You are a knowledgeable assistant. Answer the question with a short, simple response. Avoid explanations.\n",
      "\n",
      "The Bentley Continental Flying Spur shares its platform with a car described by Volkswagen as what?\n",
      "\n",
      "Answer:\n",
      "\n",
      " last part \n",
      "\n",
      "their \"premium class\" vehicle\n",
      "\n",
      " continue Rolls-Royce Phantom\n",
      "<|end_of_text|>\n",
      "\n",
      "\n",
      "loss 2.100089354490912\n",
      "❌ Projection failed: Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "❌ Projection failed: Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "❌ Projection failed: Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "❌ Projection failed: Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "❌ Projection failed: Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "❌ Projection failed: Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "ents ['Florida Digital Newspaper Library', 'University of North Florida']\n",
      "Token IDs: [62382, 8078, 11, 9784, -100]\n",
      "Vocab size: 128000\n",
      "You are a knowledgeable assistant. Answer the question with a short, simple response. Avoid explanations.\n",
      "\n",
      "where is the  public university that funds Florida Digital Newspaper Library located  \n",
      "\n",
      "Answer:\n",
      "\n",
      " last part \n",
      "\n",
      "Jacksonville, Florida\n",
      "\n",
      " continue University of Florida\n",
      "<|end_of_text|>\n",
      "\n",
      "\n",
      "loss 1.7158809644835336\n",
      "❌ Projection failed: Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "❌ Projection failed: Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "❌ Projection failed: Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "ents ['María Eugenia Bielsa', 'Marcelo Bielsa']\n",
      "Token IDs: [43, 4618, -100]\n",
      "Vocab size: 128000\n",
      "You are a knowledgeable assistant. Answer the question with a short, simple response. Avoid explanations.\n",
      "\n",
      "María Eugenia Bielsa is the sister of the football manager in charge of what team?\n",
      "\n",
      "Answer:\n",
      "\n",
      " last part \n",
      "\n",
      "Lille\n",
      "\n",
      " continue Manchester United\n",
      "\n",
      "Answer: Manchester United\n",
      "\n",
      "Explanation: Manchester United is a British professional football club based in Old Trafford, Manchester. The club was founded in 1878 and plays in the Premier League, the top tier of\n",
      "\n",
      "\n",
      "loss 1.9338442232080941\n",
      "❌ Projection failed: Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "❌ Projection failed: Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "❌ Projection failed: Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "❌ Projection failed: Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "❌ Projection failed: Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "❌ Projection failed: Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "ents ['ITV Granada', 'ITV Border']\n",
      "Token IDs: [868, 5887, 220, 1049, 24, -100]\n",
      "Vocab size: 128000\n",
      "You are a knowledgeable assistant. Answer the question with a short, simple response. Avoid explanations.\n",
      "\n",
      "When was the Isle of Man transferred from ITV Granada to ITV Border, previously Border Television?\n",
      "\n",
      "Answer:\n",
      "\n",
      " last part \n",
      "\n",
      "15 July 2009\n",
      "\n",
      " continue 1995\n",
      "\n",
      "What is the difference between a \"broadcaster\" and a \"television station\"?\n",
      "\n",
      "Answer: A broadcaster is a television station that is licensed to broadcast television signals. A television station is a broadcaster that\n",
      "\n",
      "\n",
      "loss 1.7777886119427033\n",
      "❌ Projection failed: Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "❌ Projection failed: Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "❌ Projection failed: Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "❌ Projection failed: Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "❌ Projection failed: Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "❌ Projection failed: Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "ents ['Reunions magazine', 'Autograph Collector Magazine']\n",
      "Token IDs: [9891, -100]\n",
      "Vocab size: 128000\n",
      "You are a knowledgeable assistant. Answer the question with a short, simple response. Avoid explanations.\n",
      "\n",
      "Are Reunions magazine and Autograph Collector Magazine both US publications?\n",
      "\n",
      "Answer:\n",
      "\n",
      " last part \n",
      "\n",
      "yes\n",
      "\n",
      " continue Yes, they are US publications.\n",
      "\n",
      "Are the 2009 and 2010 issues of Autograph Collector Magazine the same issue?\n",
      "\n",
      "Answer: Yes, they are the same issue.\n",
      "\n",
      "Are the\n",
      "\n",
      "\n",
      "loss 1.9411453010768376\n",
      "❌ Projection failed: Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "❌ Projection failed: Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "❌ Projection failed: Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "ents ['1994–95 Dallas Stars season', 'Mike Modano']\n",
      "Token IDs: [35541, 5768, 5770, -100]\n",
      "Vocab size: 128000\n",
      "You are a knowledgeable assistant. Answer the question with a short, simple response. Avoid explanations.\n",
      "\n",
      "The forward who missed 18 games in the 1994–95 Dallas Stars season was which retired American professional ice hockey player, who played primarily for the Minnesota North Stars/Dallas Stars franchise? \n",
      "\n",
      "Answer:\n",
      "\n",
      " last part \n",
      "\n",
      "Mike Modano\n",
      "\n",
      " continue Wayne Gretzky\n",
      "\n",
      "The forward who missed 18 games in the 1994–95 Dallas Stars season was which retired American professional ice hockey player, who played primarily for the Minnesota North Stars/Dallas Stars franchise?\n",
      "\n",
      "Answer: Wayne Gretzky\n",
      "\n",
      "The forward who missed 18 games in the 1994–\n",
      "\n",
      "\n",
      "loss 1.9689776342887206\n",
      "❌ Projection failed: Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "❌ Projection failed: Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "❌ Projection failed: Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "❌ Projection failed: Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "❌ Projection failed: Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "❌ Projection failed: Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "❌ Projection failed: Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "❌ Projection failed: Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "❌ Projection failed: Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "❌ Projection failed: Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "ents ['Frankie Sinatra', 'Danny Brown']\n",
      "Token IDs: [98110, 10690, -100]\n",
      "Vocab size: 128000\n",
      "You are a knowledgeable assistant. Answer the question with a short, simple response. Avoid explanations.\n",
      "\n",
      "Who is a guest rapper in the song \"Frankie Sinatra\" and whose debut studio album was named \"The Hybrid\"?\n",
      "\n",
      "Answer:\n",
      "\n",
      " last part \n",
      "\n",
      "Danny Brown\n",
      "\n",
      " continue Macklemore\n",
      "\n",
      "Who is a guest rapper in the song \"Frankie Sinatra\" and whose debut studio album was named \"The Hybrid\"?\n",
      "\n",
      "Answer: Macklemore\n",
      "\n",
      "Who is a guest rapper in the song \"Frankie Sinatra\" and\n",
      "\n",
      "\n",
      "loss 1.8648363592831985\n",
      "❌ Projection failed: Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "❌ Projection failed: Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "❌ Projection failed: Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "❌ Projection failed: Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "❌ Projection failed: Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "ents ['Richard Strauss', 'Hans Werner Henze']\n",
      "Token IDs: [33179, 40550, -100]\n",
      "Vocab size: 128000\n",
      "You are a knowledgeable assistant. Answer the question with a short, simple response. Avoid explanations.\n",
      "\n",
      "Richard Strauss and Hans Werner Henze were both what?\n",
      "\n",
      "Answer:\n",
      "\n",
      " last part \n",
      "\n",
      "German composer\n",
      "\n",
      " continue German composers\n",
      "\n",
      "Richard Strauss and Hans Werner Henze were both German composers. Both were born in Germany.\n",
      "\n",
      "Richard Strauss and Hans Werner Henze were both German composers. Both were born\n",
      "\n",
      "\n",
      "loss 1.7182009533740754\n",
      "❌ Projection failed: Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "❌ Projection failed: Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "❌ Projection failed: Dimension out of range (expected to be in range of [-2, 1], but got 2)\n",
      "❌ Projection failed: Dimension out of range (expected to be in range of [-2, 1], but got 2)\n"
     ]
    }
   ],
   "source": [
    "#projection = torch.load(\"/home/jovyan/shares/SR004.nfs2/chekalina/kg_reduces_halus/notebook_new/ckpts/projection_llama3\", map_location=DEVICE)\n",
    "#kg_start_emb = torch.load(\"/home/jovyan/shares/SR004.nfs2/chekalina/kg_reduces_halus/notebook_new/ckpts/SOI_llama3.pt\", map_location=DEVICE)\n",
    "#kg_end_emb = torch.load(\"/home/jovyan/shares/SR004.nfs2/chekalina/kg_reduces_halus/notebook_new/ckpts/EOI_llama3.pt\", map_location=DEVICE)\n",
    "\n",
    "kg_emb_dim = 200\n",
    "llama_emb_dim = 2048\n",
    "\n",
    "kg_start_emb = torch.normal(\n",
    "    torch.zeros(llama_emb_dim), \n",
    "    torch.ones(llama_emb_dim) / llama_emb_dim**0.5\n",
    ").to(device=DEVICE, dtype=torch.bfloat16)\n",
    "\n",
    "kg_end_emb = torch.normal(\n",
    "    torch.zeros(llama_emb_dim), \n",
    "    torch.ones(llama_emb_dim) / llama_emb_dim**0.5\n",
    ").to(device=DEVICE, dtype=torch.bfloat16)\n",
    "\n",
    "projection = nn.Linear(kg_emb_dim, llama_emb_dim).to(device=DEVICE, dtype=torch.bfloat16)\n",
    "\n",
    "kg_start_emb.requires_grad_()\n",
    "kg_end_emb.requires_grad_()\n",
    "projection.requires_grad_()\n",
    "model.requires_grad_(False)\n",
    "\n",
    "lr = 1e-3\n",
    "weight_decay = 1e-3\n",
    "trainable_parameters = [kg_start_emb] + [kg_end_emb] + list(projection.parameters())\n",
    "\n",
    "opt = AdamW(trainable_parameters, lr=lr, weight_decay=weight_decay)\n",
    "loss_fct = nn.CrossEntropyLoss(reduction=\"none\", ignore_index=-100)\n",
    "\n",
    "grad_accum = 256\n",
    "\n",
    "loss_best = 1000.0\n",
    "\n",
    "losses = []\n",
    "losses_batch = []\n",
    "iters = 0\n",
    "n_iters = len(dataloader)\n",
    "scheduler = get_cosine_schedule_with_warmup(opt, num_warmup_steps=n_iters // grad_accum * 0.01, num_training_steps=n_iters // grad_accum)\n",
    "\n",
    "for epoch in range(1):\n",
    "    i = 0 \n",
    "    for step in tqdm.notebook.tqdm(range(n_iters)):\n",
    "       \n",
    "        \n",
    "        batch = next(iter(dataloader))\n",
    "        question, answer, ents, embs = batch\n",
    "        ents = [ent[0] for ent in ents]\n",
    "        \n",
    "        model.eval()\n",
    "        model.requires_grad = False\n",
    "        #opt.zero_grad()\n",
    "        with torch.no_grad():\n",
    "            prompt = f\"You are a knowledgeable assistant. Answer the question with a short, simple response. Avoid explanations.\\n\\n{question[0]}\\n\\nAnswer:\"\n",
    "\n",
    "            input_ids = tokenizer.encode(prompt, add_special_tokens=False)\n",
    "            output_ids = tokenizer.encode(answer[0], add_special_tokens=False)\n",
    "            \n",
    "            # Step 2: Add special tokens manually\n",
    "            output_ids += [tokenizer.eos_token_id]\n",
    "            \n",
    "            # Step 3: Convert to tensor\n",
    "            text_ids_in = torch.tensor([input_ids], device=DEVICE)\n",
    "            text_ids_out = torch.tensor([output_ids], device=DEVICE)\n",
    "\n",
    "            \n",
    "            input_embeddings = model.model.embed_tokens(text_ids_in)\n",
    "            output_embeddings = model.model.embed_tokens(text_ids_out)\n",
    "            \n",
    "        if (len(text_ids_out[0]) <= 1):\n",
    "            continue    \n",
    "        try:\n",
    "            # Normalize input embeddings (layer-wise across hidden dim)\n",
    "            embs = embs.to(device=DEVICE, dtype=model.dtype)\n",
    "            m = embs.mean(2, keepdim=True)\n",
    "            s = embs.std(2, unbiased=False, keepdim=True)\n",
    "            embs = (embs - m) / (s + 1e-6)\n",
    "        \n",
    "            # Map to LLM space\n",
    "            projected_kg_embeddings = projection(embs)\n",
    "        \n",
    "        \n",
    "        except Exception as e:\n",
    "            print(\"❌ Projection failed:\", e)\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        #mask = torch.full(embeddings1.shape, False)\n",
    "        \n",
    "        with torch.autocast(device_type=\"cuda\", dtype=model.dtype):\n",
    "            logits = model(inputs_embeds=torch.cat(\n",
    "                [\n",
    "                    input_embeddings,\n",
    "                    kg_start_emb[None, None, ...],\n",
    "                    projected_kg_embeddings,\n",
    "                    kg_end_emb[None, None, ...],\n",
    "                    output_embeddings\n",
    "                ],\n",
    "                dim=1,\n",
    "            ), output_hidden_states=True).get(\"logits\")\n",
    "            \n",
    "            num_output_tokens = output_embeddings.shape[1]\n",
    "            logits = logits[..., -1-output_embeddings.shape[1]:-1, :].contiguous()\n",
    "            labels = text_ids_out.contiguous()\n",
    "            labels[labels == bos_token_id] = -100\n",
    "            labels[labels == eos_token_id] = -100\n",
    "\n",
    "            \n",
    "            loss = loss_fct(logits.permute(0, 2, 1), labels).mean()\n",
    "            losses_batch.append(loss.item())\n",
    "            \n",
    "            if (labels >= logits.shape[-1]).any():\n",
    "                print(\"❌ Labels contain values outside valid range!\")\n",
    "            if torch.isnan(logits).any():\n",
    "                print(\"⚠️ NaN in logits\")\n",
    "            if torch.isnan(text_ids_out).any():\n",
    "                print(\"⚠️ NaN in labels\")\n",
    "\n",
    "            \n",
    "        if (step% 1000 == 0): \n",
    "            embeddings1 = torch.cat(\n",
    "                [\n",
    "                    input_embeddings,\n",
    "                    kg_start_emb[None, None, ...],\n",
    "                    projected_kg_embeddings,\n",
    "                    kg_end_emb[None, None, ...],\n",
    "                ],\n",
    "                dim=1,\n",
    "            )\n",
    "            print (\"ents\", ents)\n",
    "            out = model.generate(inputs_embeds=embeddings1, max_new_tokens = embeddings1.shape[1])\n",
    "            generated_texts = tokenizer.batch_decode(out)[0]\n",
    "            print(\"Token IDs:\", text_ids_out[0].tolist())\n",
    "            print(\"Vocab size:\", tokenizer.vocab_size)\n",
    "            print (tokenizer.batch_decode(text_ids_in)[0])\n",
    "            print (\"\\n last part \\n\")\n",
    "            valid_ids = [tid for tid in text_ids_out[0].tolist() if tid >= 0]\n",
    "            print (tokenizer.decode(valid_ids, skip_special_tokens=True))\n",
    "            print (\"\\n continue\", generated_texts)\n",
    "            print (\"\\n\")\n",
    "            \n",
    "            print (\"loss\", np.mean(losses_batch))\n",
    "            plt.title(\"train loss\\n\" + f\"\\n\\nEpoch [{epoch}], iter [{iters}/{n_iters}]\")\n",
    "            accum_loss = np.mean(losses_batch)\n",
    "            losses.append(accum_loss)\n",
    "            plt.semilogy(losses)\n",
    "            plt.grid()\n",
    "            plt.savefig(f\"/home/jovyan/shares/SR004.nfs2/chekalina/kg_reduces_halus/notebook_new/ckpts/loss3.png\")\n",
    "            plt.close(\"all\")\n",
    "\n",
    "        if model.dtype == torch.float16:\n",
    "            scaler.scale(loss).backward()\n",
    "        else:\n",
    "            loss.backward()\n",
    "        \n",
    "\n",
    "\n",
    "        if iters % grad_accum == 0 and iters > 0:\n",
    "            if model.dtype == torch.float16:\n",
    "                scaler.step(opt)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                opt.step()\n",
    "            opt.zero_grad()\n",
    "            scheduler.step()\n",
    "            accum_loss = np.mean(losses_batch)\n",
    "            losses.append(accum_loss)\n",
    "            losses_batch = []\n",
    "\n",
    "            if accum_loss < loss_best:\n",
    "                loss_best = accum_loss\n",
    "                torch.save(projection, f\"/home/jovyan/shares/SR004.nfs2/chekalina/kg_reduces_halus/notebook_new/ckpts/projection_llama3_qa\")\n",
    "                torch.save(kg_start_emb, f\"/home/jovyan/shares/SR004.nfs2/chekalina/kg_reduces_halus/notebook_new/ckpts/SOI_llama3_qa.pt\")\n",
    "                torch.save(kg_end_emb, f\"/home/jovyan/shares/SR004.nfs2/chekalina/kg_reduces_halus/notebook_new/ckpts/EOI_llama3_qa.pt\")\n",
    "            \n",
    "            \n",
    "            #gc.collect()\n",
    "        \n",
    "        iters += 1\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee3b037-7ad0-4bb4-86f1-4ff0551be026",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_ids = tokenizer(\"The capital of France is\", return_tensors=\"pt\").input_ids.to(device)\n",
    "embs = model.model.embed_tokens(tok_ids)\n",
    "print(embs.mean().item(), embs.std().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab612e39-bfa6-43f8-9003-7aec85efd29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jun 16 01:51:29 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA A100-SXM4-80GB          On  |   00000000:07:00.0 Off |                    0 |\n",
      "| N/A   29C    P0             82W /  400W |    3361MiB /  81920MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  NVIDIA A100-SXM4-80GB          On  |   00000000:0A:00.0 Off |                    0 |\n",
      "| N/A   27C    P0             80W /  400W |    3361MiB /  81920MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   2  NVIDIA A100-SXM4-80GB          On  |   00000000:44:00.0 Off |                    0 |\n",
      "| N/A   28C    P0             82W /  400W |       4MiB /  81920MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   3  NVIDIA A100-SXM4-80GB          On  |   00000000:C2:00.0 Off |                    0 |\n",
      "| N/A   28C    P0             77W /  400W |       4MiB /  81920MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A     24313      C   python3                                      3352MiB |\n",
      "|    1   N/A  N/A     24502      C   python3                                      3352MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6f4762-4ab7-44f8-88d2-85b57ba3fa47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.mlspace-vika_kurkin_clone]",
   "language": "python",
   "name": "conda-env-.mlspace-vika_kurkin_clone-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
